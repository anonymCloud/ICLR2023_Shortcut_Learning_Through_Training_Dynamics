{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "from tqdm import tqdm   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, pdb\n",
    "import torch, torchvision\n",
    "import pickle\n",
    "import time\n",
    "from PIL import Image\n",
    "# from pykeops.torch import LazyTensor\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import models, datasets\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "df_tube = pd.read_csv('xxx')\n",
    "df_notube = pd.read_csv('xxx')\n",
    "df_all = pd.read_csv('xxx')\n",
    "class_name = 'Pneumothorax' # column name as per the outcomes.csv file\n",
    "\n",
    "class_prob = class_name + '_prob'\n",
    "fpr_tube, tpr_tube, thresholds1 = metrics.roc_curve(df_tube[class_name], df_tube[class_prob])\n",
    "fpr_notube, tpr_notube, thresholds2 = metrics.roc_curve(df_notube[class_name], df_notube[class_prob])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_all[class_name], df_all[class_prob])\n",
    "auc_tube = metrics.auc(fpr_tube,tpr_tube)\n",
    "auc_notube = metrics.auc(fpr_notube,tpr_notube)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "plt.plot(fpr,tpr,label='All (AUC %.2f)'%(auc))\n",
    "plt.plot(fpr_tube,tpr_tube,label='Chest Drains (AUC %.2f)'%(auc_tube))\n",
    "plt.plot(fpr_notube,tpr_notube,label='No Chest Drains (AUC %.2f)'%(auc_notube))\n",
    "\n",
    "\n",
    "plt.title('%s Detection' %(class_name))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tube[' pneumothorax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_correlations(df, disease, shortcut):\n",
    "    \n",
    "    a = len(df[(df[disease]==1)&(df[shortcut]==0)])\n",
    "    b = len(df[(df[disease]==1)&(df[shortcut]==1)])\n",
    "    c = len(df[(df[disease]==0)&(df[shortcut]==0)])\n",
    "    d = len(df[(df[disease]==0)&(df[shortcut]==1)])\n",
    "\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap([[a,b],[c,d]], annot=True, fmt='g', ax=ax, cmap='coolwarm')  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel(shortcut);ax.set_ylabel(disease)\n",
    "    ax.set_title('Correlation Analysis')\n",
    "    ax.xaxis.set_ticklabels(['0', '1']); ax.yaxis.set_ticklabels(['1', '0'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xxx')\n",
    "\n",
    "list1 = ['effusion', 'opacity', 'pneumothorax',\n",
    "       'edema', 'atelectasis', 'consolidation', 'pneumonia',\n",
    "       'congestion', 'cardiomegaly', 'fracture', 'device',\n",
    "       'emphysema', 'mass', 'hernia', 'lesion']\n",
    "\n",
    "# list2 = ['normal', 'clear', 'sharp', 'sharply', 'unremarkable',\n",
    "#        'intact', 'stable', 'free', 'tube', 'process',\n",
    "#        'abnormality', 'enlarge', 'tip', 'low', 'line',\n",
    "#        'catheter', 'air', 'tortuous',\n",
    "#        'lead', 'disease', 'calcification', 'prominence', \n",
    "#        'engorgement', 'picc', 'clip', 'elevation', 'expand', 'nodule', 'wire',\n",
    "#        'fluid', 'degenerative', 'pacemaker', 'thicken', 'marking', 'scar',\n",
    "#        'hyperinflate', 'blunt', 'loss', 'widen', 'collapse', 'density',\n",
    "#        'aerate', 'crowd', 'infiltrate', 'obscure',\n",
    "#        'deformity', 'drainage', 'distention', 'shift', 'stent',\n",
    "#        'pressure', 'finding', 'borderline', 'hardware', 'dilation',\n",
    "#        'chf', 'redistribution', 'aspiration', 'tail_abnorm_obs',\n",
    "#        'excluded_obs']\n",
    "\n",
    "list2 = ['tube', 'tip', 'low', 'line', 'catheter', 'nodule', 'wire',\n",
    "       'pacemaker', 'marking', 'scar','drainage', 'stent',\n",
    "       'hardware']\n",
    "\n",
    "for disease in tqdm(list1):\n",
    "    for shortcut in tqdm(list2):\n",
    "        analyse_correlations(df, disease, shortcut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize images in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a list of img paths and plots grid of images\n",
    "def plot_images(img_list, rows, cols, preds=None, labels=None):\n",
    "    plt.figure(figsize=(7.5*cols,7.5*rows))\n",
    "    for i in range(rows*cols):\n",
    "        plt.subplot(rows,cols,i+1)\n",
    "        if type(img_list[0])==str:\n",
    "            img = plt.imread(img_list[i])\n",
    "        elsek:\n",
    "            img = img_list[i]\n",
    "        plt.imshow(img)\n",
    "        if preds is not None:\n",
    "            if preds[i]==labels[i]:\n",
    "                plt.title('pred:%d, label:%d' %(preds[i],labels[i]), fontdict={'color':'g','fontsize':15})\n",
    "            else:\n",
    "                plt.title('pred:%d, label:%d' %(preds[i],labels[i]), fontdict={'color':'r','fontsize':15})\n",
    "    plt.show()\n",
    "\n",
    "# search for images in the dataset with the given conditions\n",
    "def viz_dataset(df, conditions=None, path_col='path', rows=3, cols=3):\n",
    "    if conditions is not None:\n",
    "        bool_arr = (df[conditions[0]['name']]==conditions[0]['value'])\n",
    "        for cond in conditions[1:]:\n",
    "            bool_arr = (bool_arr) & (df[cond['name']]==cond['value'])\n",
    "        df = df[bool_arr]\n",
    "    df = df.sample(frac=1)\n",
    "    plot_images(list(df.head(rows*cols)[path_col]),rows,cols)\n",
    "\n",
    "def viz_cam_maps(model, loader, rows, cols):\n",
    "    for batch in loader:\n",
    "        imgs = batch['img'].to('cuda')\n",
    "        labels = batch['lab'].squeeze().cpu().numpy()\n",
    "        targets = [ClassifierOutputTarget(0)]*len(imgs)\n",
    "        target_layers = [model.features[-1]]\n",
    "\n",
    "        # get model predictions\n",
    "        model = model.to('cuda')\n",
    "        preds = model(imgs)\n",
    "        preds = (preds>0).squeeze().cpu().numpy().astype(float)\n",
    "\n",
    "        # fetch Class Activation Maps (cams)\n",
    "        cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
    "        grayscale_cams = cam(input_tensor=imgs, targets=targets, aug_smooth=True, eigen_smooth=True)\n",
    "        \n",
    "        # overlay cam on original images\n",
    "        imgs = imgs.squeeze().unsqueeze(-1).detach().cpu().numpy()\n",
    "        img_list = []   # list of ndarray imgs\n",
    "        for i in range(rows*cols):\n",
    "            cam_op = show_cam_on_image(imgs[i]*250, grayscale_cams[i]*0.5, use_rgb=True)\n",
    "            img_list.append(cam_op)\n",
    "\n",
    "        # plot overlays\n",
    "        plot_images(img_list,rows,cols,preds,labels)\n",
    "        break\n",
    "\n",
    "\n",
    "class center_crop(object):\n",
    "    def crop_center(self, img):\n",
    "        _, y, x = img.shape\n",
    "        crop_size = np.min([y,x])\n",
    "        startx = x // 2 - (crop_size // 2)\n",
    "        starty = y // 2 - (crop_size // 2)\n",
    "        return img[:, starty:starty + crop_size, startx:startx + crop_size]\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.crop_center(img)\n",
    "\n",
    "class normalize(object):\n",
    "    def normalize_(self, img, maxval=255):\n",
    "        img = (img)/(maxval)\n",
    "        return img\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.normalize_(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAD-CAM PLOTS\n",
    "\n",
    "# user hyperparams\n",
    "ckpt_path = 'xxx'\n",
    "data_file = 'xxx'\n",
    "class_names = ['pneumothorax']\n",
    "rows = 16\n",
    "cols = 4\n",
    "\n",
    "\n",
    "model = torch.load(ckpt_path)\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((256,256)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(center_crop()),\n",
    "        torchvision.transforms.Lambda(normalize())\n",
    "    ])\n",
    "dataset = datasets.MIMIC_Dataset(csvpath=data_file, class_names=class_names, transform=transforms, seed=0)\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                    batch_size=rows*cols,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=4, \n",
    "                                    pin_memory=True)\n",
    "\n",
    "viz_cam_maps(model.to('cuda'), loader, rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xxx')\n",
    "viz_dataset(df, [{'name':'pneumothorax','value':1},{'name':'tube','value':1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xxx')\n",
    "viz_dataset(df,rows=9,cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Hidden Stratifications (csv files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('xxx')\n",
    "bool_tubes = (df_test['catheter']==1) | (df_test['tube']==1) | (df_test['drainage']==1)\n",
    "bool_disease = (df_test['pneumothorax']==1)\n",
    "# bool_ = (df_test['pacemaker']==1) & (df_test['wire']==1) & (df_test['catheter']==1)\n",
    "df_pos_tube = df_test[bool_disease & bool_tubes]\n",
    "df_pos_notube = df_test[bool_disease & ~bool_tubes]\n",
    "df_neg_tube = df_test[~bool_disease & bool_tubes]\n",
    "df_neg_notube = df_test[~bool_disease & ~bool_tubes]\n",
    "\n",
    "df_all_tubes = pd.concat([df_pos_tube,df_neg_tube])\n",
    "df_no_tubes = pd.concat([df_pos_notube,df_neg_notube])\n",
    "df_pos_tubes = pd.concat([df_pos_tube,df_neg_notube])\n",
    "df_neg_tubes = pd.concat([df_pos_notube,df_neg_tube])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz_dataset(df, [{'name':'pneumothorax','value':1},{'name':'catheter','value':0},{'name':'tube','value':0},{'name':'drainage','value':0},{'name':'pacemaker','value':0},{'name':'wire','value':0},{'name':'line','value':0},{'name':'tip','value':0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RadGraph annotations (for various tubes, catheters)\n",
    "We are looking for tubes and catheters that are OBS-DP and their modifiers denote the type of tube or catheter.\n",
    "Specific tubes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all images with tubes and catheters and get their types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df,df,how='left',left_on=['target','subject_id','study_id'],right_on=['source','subject_id','study_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[(df_final['relation_x']=='located_at')&(df_final['token_x']=='catheter')][['subject_id','study_id','token_x','relation_x','token_y','label_x']].to_csv('temp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique tubes and cathters along with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame()\n",
    "names = np.unique(df_caths['token_y'],return_counts=True)[0]\n",
    "counts = np.unique(df_caths['token_y'],return_counts=True)[1]\n",
    "df_temp['cath_location'] = names\n",
    "df_temp['count'] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv('./mimic_unique_caths_located_at(temp).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we are interested in the following:\n",
    "pigtail (catheter)\n",
    "pleural (tube/catheter)\n",
    "chest (tube)\n",
    "thoracostomy (tube)\n",
    "\n",
    "find specific tubes/catheters and their image locations\n",
    "we are basically interested in tubes and catheters that are OBS-DP\n",
    "and types we are interested in:\n",
    "pigtail catheter, pleural/pleurX/pleurex tube/catheter, chest tube, thoracostomy tube\n",
    "the relationship is different for each\n",
    "for eg., \"pigtail\" modifies \"cathter\", whereas \"tube\" is located at \"pleural\"\n",
    "some tokens can have both \"modify\" and \"located at\" relationships, like \"chest tube\"\n",
    "\"tube\" is located at \"chest\" and \"chest\" modifies \"tube\" both kinds of data were found in the report!\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caths = df_caths[df_caths['label_x']=='OBS-DP'].loc[df_caths['token_y'].str.contains('pleur',case=False)]\n",
    "df_caths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caths = df_caths[['subject_id','study_id']].drop_duplicates()\n",
    "df_caths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caths = pd.merge(df_caths, df_all,  how='inner', left_on=['subject_id','study_id'], right_on=['patient_id','study_id'])\n",
    "df_caths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caths.to_csv('./temp_df_pleural_caths.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Shortcut and Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either df or path should be provided. path overrides df\n",
    "# provide split info if you're only interested in subset of data\n",
    "def create_shortcut(spurious_corr, df=None, path=None, split_info=None, skew=1.0):\n",
    "    \n",
    "    if path is not None:\n",
    "        df = pd.read_csv(path)\n",
    "    \n",
    "    if split_info is not None:\n",
    "        col = split_info['col_name']\n",
    "        values = split_info['values']\n",
    "        arr = [False]*len(df)\n",
    "        for val in values:\n",
    "            arr = ( arr | (df[col]==val) )\n",
    "        df = df[arr]\n",
    "        \n",
    "    bool_arr = {}\n",
    "    bool_arr['core'] = []\n",
    "    bool_arr['spurious'] = []\n",
    "    for key in spurious_corr:\n",
    "        if len(spurious_corr[key])==2:\n",
    "            flag = 'range' # it's a continuous variable, apply <,>=\n",
    "        elif len(spurious_corr[key])==3:\n",
    "            flag = 'hard' # it's a discrete assignment, apply ==\n",
    "        else:\n",
    "            raise('Invalid \"spurious_corr\" dictionary')\n",
    "            \n",
    "        if flag=='range':\n",
    "            attr = spurious_corr[key][0]\n",
    "            thresh = spurious_corr[key][1]\n",
    "            \n",
    "            arr_temp = (df[attr]<thresh)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "            \n",
    "            arr_temp = (df[attr]>=thresh)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "        elif flag=='hard':\n",
    "            attr = spurious_corr[key][0]\n",
    "            thresh1 = spurious_corr[key][1]\n",
    "            thresh2 = spurious_corr[key][2]\n",
    "            \n",
    "            arr_temp = (df[attr]==thresh1)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "            \n",
    "            arr_temp = (df[attr]==thresh2)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "        else:\n",
    "            raise('Invalid flag variable')\n",
    "            \n",
    "    # all diagonal elements must be present in most cases\n",
    "    arr00 = ((bool_arr['core'][0])&(bool_arr['spurious'][0]))\n",
    "    arr11 = ((bool_arr['core'][1])&(bool_arr['spurious'][1]))\n",
    "    arr01 = ((bool_arr['core'][0])&(bool_arr['spurious'][1]))\n",
    "    arr10 = ((bool_arr['core'][1])&(bool_arr['spurious'][0]))\n",
    "    \n",
    "    df00 = df[arr00]\n",
    "    df11 = df[arr11]\n",
    "    df01 = df[arr01]\n",
    "    df10 = df[arr10]\n",
    "    df_diag = pd.concat([df00,df11]).sample(frac=1)\n",
    "    df_nondiag = pd.DataFrame()\n",
    "    if skew == 1.0:\n",
    "        df_final = df_diag\n",
    "    else:\n",
    "        coeff = (1/skew-1)\n",
    "        num_nondiag = int(len(df_diag)*coeff) # number of non-diag samples needed\n",
    "                                                # to satisfy skew requirement\n",
    "        df_nondiag = pd.concat([df10,df01]).sample(frac=1)\n",
    "        if len(df_nondiag)>=num_nondiag: # meaning you have required num of samples\n",
    "            df_nondiag = df_nondiag.sample(n=num_nondiag)\n",
    "        else:\n",
    "            # reduce number of diag samples to fulfill ratio\n",
    "            num_diag = int(len(df_nondiag)/coeff)\n",
    "            df_diag = df_diag.sample(n=num_diag)\n",
    "            \n",
    "        df_final = pd.concat([df_diag,df_nondiag]).sample(frac=1)    \n",
    "        \n",
    "    # get group stats\n",
    "    bool_arr = {}\n",
    "    bool_arr['core'] = []\n",
    "    bool_arr['spurious'] = []\n",
    "    for key in spurious_corr:\n",
    "        if len(spurious_corr[key])==2:\n",
    "            flag = 'range' # it's a continuous variable, apply <,>=\n",
    "        elif len(spurious_corr[key])==3:\n",
    "            flag = 'hard' # it's a discrete assignment, apply =\n",
    "        else:\n",
    "            raise('Invalid \"spurious_corr\" dictionary')\n",
    "            \n",
    "        if flag=='range':\n",
    "            attr = spurious_corr[key][0]\n",
    "            thresh = spurious_corr[key][1]\n",
    "            \n",
    "            arr_temp = (df_final[attr]<thresh)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "            \n",
    "            arr_temp = (df_final[attr]>=thresh)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "        elif flag=='hard':\n",
    "            attr = spurious_corr[key][0]\n",
    "            thresh1 = spurious_corr[key][1]\n",
    "            thresh2 = spurious_corr[key][2]\n",
    "            \n",
    "            arr_temp = (df_final[attr]==thresh1)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "            \n",
    "            arr_temp = (df_final[attr]==thresh2)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "        else:\n",
    "            raise('Invalid flag variable')\n",
    "\n",
    "    arr00 = ((bool_arr['core'][0])&(bool_arr['spurious'][0]))\n",
    "    arr11 = ((bool_arr['core'][1])&(bool_arr['spurious'][1]))\n",
    "    arr01 = ((bool_arr['core'][0])&(bool_arr['spurious'][1]))\n",
    "    arr10 = ((bool_arr['core'][1])&(bool_arr['spurious'][0]))\n",
    "    \n",
    "    df00 = df_final[arr00]\n",
    "    df11 = df_final[arr11]\n",
    "    df01 = df_final[arr01]\n",
    "    df10 = df_final[arr10]\n",
    "    \n",
    "    group_dfs = {'df_c0_s0':df00,'df_c0_s1':df01,'df_c1_s0':df10,'df_c1_s1':df11}\n",
    "\n",
    "    print('core: ')\n",
    "    print(spurious_corr['core'])\n",
    "    print('\\n')\n",
    "    print('spurious: ')\n",
    "    print(spurious_corr['spurious'])\n",
    "    print('\\n')\n",
    "    print('Groups: ')\n",
    "    print('len(df_c0_s0): %d;          len(df_c0_s1): %d' %(len(df00),len(df01)))\n",
    "    print('len(df_c1_s0): %d;          len(df_c1_s1): %d' %(len(df10),len(df11)))\n",
    "\n",
    "    return df_final, group_dfs\n",
    "\n",
    "def retrieve_groups(spurious_corr, df=None, path=None):\n",
    "    \n",
    "    if path is not None:\n",
    "        df = pd.read_csv(path)    \n",
    "        \n",
    "    # get group stats\n",
    "    bool_arr = {}\n",
    "    bool_arr['core'] = []\n",
    "    bool_arr['spurious'] = []\n",
    "    for key in spurious_corr:\n",
    "        if len(spurious_corr[key])==2:\n",
    "            flag = 'range' # it's a continuous variable, apply <,>=\n",
    "        elif len(spurious_corr[key])==3:\n",
    "            flag = 'hard' # it's a discrete assignment, apply =\n",
    "        else:\n",
    "            raise('Invalid \"spurious_corr\" dictionary')\n",
    "            \n",
    "        if flag=='range':\n",
    "            attr = spurious_corr[key][0]\n",
    "            thresh = spurious_corr[key][1]\n",
    "            \n",
    "            arr_temp = (df[attr]<thresh)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "            \n",
    "            arr_temp = (df[attr]>=thresh)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "        elif flag=='hard':\n",
    "            attr = spurious_corr[key][0]\n",
    "            thresh1 = spurious_corr[key][1]\n",
    "            thresh2 = spurious_corr[key][2]\n",
    "            \n",
    "            arr_temp = (df[attr]==thresh1)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "            \n",
    "            arr_temp = (df[attr]==thresh2)\n",
    "            bool_arr[key].append(arr_temp)\n",
    "        else:\n",
    "            raise('Invalid flag variable')\n",
    "\n",
    "    arr00 = ((bool_arr['core'][0])&(bool_arr['spurious'][0]))\n",
    "    arr11 = ((bool_arr['core'][1])&(bool_arr['spurious'][1]))\n",
    "    arr01 = ((bool_arr['core'][0])&(bool_arr['spurious'][1]))\n",
    "    arr10 = ((bool_arr['core'][1])&(bool_arr['spurious'][0]))\n",
    "    \n",
    "    df00 = df[arr00]\n",
    "    df11 = df[arr11]\n",
    "    df01 = df[arr01]\n",
    "    df10 = df[arr10]\n",
    "    \n",
    "    group_dfs = {'df_c0_s0':df00,'df_c0_s1':df01,'df_c1_s0':df10,'df_c1_s1':df11}\n",
    "\n",
    "    print('core: ')\n",
    "    print(spurious_corr['core'])\n",
    "    print('\\n')\n",
    "    print('spurious: ')\n",
    "    print(spurious_corr['spurious'])\n",
    "    print('\\n')\n",
    "    print('Groups: ')\n",
    "    print('len(df_c0_s0): %d;          len(df_c0_s1): %d' %(len(df00),len(df01)))\n",
    "    print('len(df_c1_s0): %d;          len(df_c1_s1): %d' %(len(df10),len(df11)))\n",
    "\n",
    "    return group_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_in_years', 50.0]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 4781;          len(df_c0_s1): 42687\n",
      "len(df_c1_s0): 2257;          len(df_c1_s1): 212\n"
     ]
    }
   ],
   "source": [
    "# user hyperparams\n",
    "spurious_corr = {'core':['Pneumothorax',0.0,1.0], 'spurious':['age_in_years',50.0]}\n",
    "split_info = {'col_name': 'val_train_split', 'values':[0,1]}\n",
    "path = 'xxx'\n",
    "\n",
    "df_shortcut, groups = create_shortcut(spurious_corr, path=path, split_info=split_info, skew=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['view_pa0_ap1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 4111;          len(df_c0_s1): 35283\n",
      "len(df_c1_s0): 2810;          len(df_c1_s1): 121\n"
     ]
    }
   ],
   "source": [
    "path = 'xxx/pneum_view_0p1.csv'\n",
    "spurious_corr = {'core':['Pneumothorax',0.0,1.0], 'spurious':['view_pa0_ap1',0,1]}\n",
    "groups = retrieve_groups(spurious_corr=spurious_corr, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 4297;          len(df_c0_s1): 37958\n",
      "len(df_c1_s0): 2213;          len(df_c1_s1): 166\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 9644;          len(df_c0_s1): 37958\n",
      "len(df_c1_s0): 2213;          len(df_c1_s1): 398\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 16541;          len(df_c0_s1): 37958\n",
      "len(df_c1_s0): 2213;          len(df_c1_s1): 675\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 25669;          len(df_c0_s1): 37958\n",
      "len(df_c1_s0): 2213;          len(df_c1_s1): 1111\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 38545;          len(df_c0_s1): 37958\n",
      "len(df_c1_s0): 2213;          len(df_c1_s1): 1626\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 49808;          len(df_c0_s1): 32728\n",
      "len(df_c1_s0): 1904;          len(df_c1_s1): 2141\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 49808;          len(df_c0_s1): 21064\n",
      "len(df_c1_s0): 1199;          len(df_c1_s1): 2141\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['gender_m0f1', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 49808;          len(df_c0_s1): 12295\n",
      "len(df_c1_s0): 692;          len(df_c1_s1): 2141\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 4751;          len(df_c0_s1): 42687\n",
      "len(df_c1_s0): 2257;          len(df_c1_s1): 242\n",
      "==========<18.9827931172469>\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 10720;          len(df_c0_s1): 42687\n",
      "len(df_c1_s0): 2257;          len(df_c1_s1): 516\n",
      "==========<19.259646592138477>\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 18422;          len(df_c0_s1): 42687\n",
      "len(df_c1_s0): 2257;          len(df_c1_s1): 839\n",
      "==========<19.738049095607234>\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 28612;          len(df_c0_s1): 42687\n",
      "len(df_c1_s0): 2257;          len(df_c1_s1): 1350\n",
      "==========<19.766842251178264>\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 42937;          len(df_c0_s1): 42687\n",
      "len(df_c1_s0): 2257;          len(df_c1_s1): 2007\n",
      "==========<20.080675422138835>\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 45079;          len(df_c0_s1): 29898\n",
      "len(df_c1_s0): 1552;          len(df_c1_s1): 2097\n",
      "==========<20.547273225541243>\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 45079;          len(df_c0_s1): 19249\n",
      "len(df_c1_s0): 969;          len(df_c1_s1): 2097\n",
      "==========<20.981082844096544>\n",
      "core: \n",
      "['Pneumothorax', 0.0, 1.0]\n",
      "\n",
      "\n",
      "spurious: \n",
      "['age_geq_50', 0, 1]\n",
      "\n",
      "\n",
      "Groups: \n",
      "len(df_c0_s0): 45079;          len(df_c0_s1): 11187\n",
      "len(df_c1_s0): 607;          len(df_c1_s1): 2097\n",
      "==========<20.808431952662723>\n"
     ]
    }
   ],
   "source": [
    "## helps you to know num_negative/numpositive to train your classifier with weighted cross entropy\n",
    "# for i in range(1,9):\n",
    "#     path = f'xxx/pneum_age_50_0p{i}.csv'\n",
    "#     spurious_corr = {'core':['Pneumothorax',0.0,1.0], 'spurious':['age_geq_50',0,1]}\n",
    "#     groups = retrieve_groups(spurious_corr=spurious_corr, path=path)\n",
    "#     num = (len(groups['df_c0_s0'])+len(groups['df_c0_s1']))/(len(groups['df_c1_s0'])+len(groups['df_c1_s1']))\n",
    "#     print(f'==========<{num}>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_c0_s0':                                                     path  \\\n",
       " 8      /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 35     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 47     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 53     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 58     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " ...                                                  ...   \n",
       " 42294  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42301  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42303  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42310  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42311  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " \n",
       "                      labels  Follow-up #  patient_id   age gender view  \\\n",
       " 8                No Finding            2       21057  027Y      F   PA   \n",
       " 35              Atelectasis            3       15328  056Y      M   PA   \n",
       " 47               No Finding            3       19118  038Y      M   PA   \n",
       " 53               No Finding            1        1957  026Y      M   PA   \n",
       " 58                     Mass            4       22948  068Y      M   PA   \n",
       " ...                     ...          ...         ...   ...    ...  ...   \n",
       " 42294  Effusion|Mass|Nodule            0       13499  033Y      M   PA   \n",
       " 42301            No Finding           25       20450  059Y      M   PA   \n",
       " 42303    Pleural_Thickening            0       16628  063Y      F   PA   \n",
       " 42310            No Finding            0        5315  051Y      M   PA   \n",
       " 42311            No Finding            0        2520  072Y      M   PA   \n",
       " \n",
       "        OriginalImage[Width  Height]  OriginalImagePixelSpacing[x  ...  \\\n",
       " 8                     2482     2697                     0.143000  ...   \n",
       " 35                    2992     2991                     0.143000  ...   \n",
       " 47                    2834     2991                     0.143000  ...   \n",
       " 53                    2048     2500                     0.168000  ...   \n",
       " 58                    2992     2991                     0.143000  ...   \n",
       " ...                    ...      ...                          ...  ...   \n",
       " 42294                 2992     2991                     0.143000  ...   \n",
       " 42301                 3056     2544                     0.139000  ...   \n",
       " 42303                 2642     2991                     0.143000  ...   \n",
       " 42310                 2500     2048                     0.171000  ...   \n",
       " 42311                 2021     2016                     0.194311  ...   \n",
       " \n",
       "        No Finding  val_train_split  test_split  all_zeros  tube_prob  \\\n",
       " 8               1                1           1          0   0.032348   \n",
       " 35              0                1           1          0   0.013156   \n",
       " 47              1                1           1          0   0.014349   \n",
       " 53              1                1           1          0   0.001880   \n",
       " 58              0                1           1          0   0.005961   \n",
       " ...           ...              ...         ...        ...        ...   \n",
       " 42294           0                1           1          0   0.438028   \n",
       " 42301           1                1           1          0   0.163730   \n",
       " 42303           0                1           1          0   0.021905   \n",
       " 42310           1                1           1          0   0.003958   \n",
       " 42311           1                1           1          0   0.070441   \n",
       " \n",
       "        age_in_years  age_geq_50  gender_m0f1  view_pa0_ap1  tube_geq_0p5  \n",
       " 8              27.0           0            1             0             0  \n",
       " 35             56.0           1            0             0             0  \n",
       " 47             38.0           0            0             0             0  \n",
       " 53             26.0           0            0             0             0  \n",
       " 58             68.0           1            0             0             0  \n",
       " ...             ...         ...          ...           ...           ...  \n",
       " 42294          33.0           0            0             0             0  \n",
       " 42301          59.0           1            0             0             0  \n",
       " 42303          63.0           1            1             0             0  \n",
       " 42310          51.0           1            0             0             0  \n",
       " 42311          72.0           1            0             0             0  \n",
       " \n",
       " [4111 rows x 35 columns],\n",
       " 'df_c0_s1':                                                     path  \\\n",
       " 0      /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 1      /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 2      /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 3      /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 4      /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " ...                                                  ...   \n",
       " 42319  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42320  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42322  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42323  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42324  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " \n",
       "                                             labels  Follow-up #  patient_id  \\\n",
       " 0                                       No Finding           42       13616   \n",
       " 1                                         Effusion          102       15530   \n",
       " 2                                       No Finding            3       15653   \n",
       " 3                                       No Finding            1        9401   \n",
       " 4                                       No Finding            2        1526   \n",
       " ...                                            ...          ...         ...   \n",
       " 42319  Atelectasis|Infiltration|Pleural_Thickening            3       15137   \n",
       " 42320                                   No Finding            0        6465   \n",
       " 42322                                Consolidation           39       18867   \n",
       " 42323                                     Effusion            2       12829   \n",
       " 42324                                     Effusion           21        6039   \n",
       " \n",
       "         age gender view  OriginalImage[Width  Height]  \\\n",
       " 0      063Y      M   AP                 2500     2048   \n",
       " 1      020Y      M   AP                 3056     2544   \n",
       " 2      055Y      F   AP                 2500     2048   \n",
       " 3      080Y      M   AP                 2500     2048   \n",
       " 4      015Y      M   AP                 2048     2500   \n",
       " ...     ...    ...  ...                  ...      ...   \n",
       " 42319  059Y      M   AP                 2500     2048   \n",
       " 42320  014Y      M   AP                 2500     2048   \n",
       " 42322  034Y      F   AP                 2500     2048   \n",
       " 42323  053Y      M   AP                 2500     2048   \n",
       " 42324  059Y      M   AP                 2500     2048   \n",
       " \n",
       "        OriginalImagePixelSpacing[x  ...  No Finding  val_train_split  \\\n",
       " 0                            0.168  ...           1                1   \n",
       " 1                            0.139  ...           0                1   \n",
       " 2                            0.168  ...           1                1   \n",
       " 3                            0.168  ...           1                1   \n",
       " 4                            0.168  ...           1                1   \n",
       " ...                            ...  ...         ...              ...   \n",
       " 42319                        0.168  ...           0                1   \n",
       " 42320                        0.168  ...           1                1   \n",
       " 42322                        0.168  ...           0                1   \n",
       " 42323                        0.168  ...           0                1   \n",
       " 42324                        0.168  ...           0                1   \n",
       " \n",
       "        test_split  all_zeros  tube_prob  age_in_years  age_geq_50  \\\n",
       " 0               1          0   0.154528          63.0           1   \n",
       " 1               1          0   0.151567          20.0           0   \n",
       " 2               1          0   0.395451          55.0           1   \n",
       " 3               1          0   0.005176          80.0           1   \n",
       " 4               1          0   0.025375          15.0           0   \n",
       " ...           ...        ...        ...           ...         ...   \n",
       " 42319           1          0   0.193242          59.0           1   \n",
       " 42320           1          0   0.025289          14.0           0   \n",
       " 42322           1          0   0.069859          34.0           0   \n",
       " 42323           1          0   0.089136          53.0           1   \n",
       " 42324           1          0   0.334760          59.0           1   \n",
       " \n",
       "        gender_m0f1  view_pa0_ap1  tube_geq_0p5  \n",
       " 0                0             1             0  \n",
       " 1                0             1             0  \n",
       " 2                1             1             0  \n",
       " 3                0             1             0  \n",
       " 4                0             1             0  \n",
       " ...            ...           ...           ...  \n",
       " 42319            0             1             0  \n",
       " 42320            0             1             0  \n",
       " 42322            1             1             0  \n",
       " 42323            0             1             0  \n",
       " 42324            0             1             0  \n",
       " \n",
       " [35283 rows x 35 columns],\n",
       " 'df_c1_s0':                                                     path  \\\n",
       " 15     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 43     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 50     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 73     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 93     /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " ...                                                  ...   \n",
       " 42227  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42243  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42293  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42312  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42321  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " \n",
       "                                                   labels  Follow-up #  \\\n",
       " 15     Effusion|Infiltration|Pleural_Thickening|Pneum...           23   \n",
       " 43                                          Pneumothorax           59   \n",
       " 50                              Atelectasis|Pneumothorax           14   \n",
       " 73                                          Pneumothorax            4   \n",
       " 93                     Atelectasis|Effusion|Pneumothorax            5   \n",
       " ...                                                  ...          ...   \n",
       " 42227                       Fibrosis|Nodule|Pneumothorax            0   \n",
       " 42243                                       Pneumothorax            0   \n",
       " 42293                         Consolidation|Pneumothorax           10   \n",
       " 42312                              Effusion|Pneumothorax            8   \n",
       " 42321                                       Pneumothorax           48   \n",
       " \n",
       "        patient_id   age gender view  OriginalImage[Width  Height]  \\\n",
       " 15          17324  035Y      F   PA                 2642     2437   \n",
       " 43          11460  016Y      M   PA                 2858     2753   \n",
       " 50          20318  060Y      M   PA                 2992     2991   \n",
       " 73          27416  074Y      F   PA                 2992     2991   \n",
       " 93           7670  045Y      F   PA                 2674     2761   \n",
       " ...           ...   ...    ...  ...                  ...      ...   \n",
       " 42227       26746  065Y      M   PA                 2992     2991   \n",
       " 42243       14143  019Y      M   PA                 2322     2991   \n",
       " 42293         491  038Y      M   PA                 2021     2021   \n",
       " 42312        7056  056Y      M   PA                 2992     2991   \n",
       " 42321       11355  028Y      M   PA                 2982     2991   \n",
       " \n",
       "        OriginalImagePixelSpacing[x  ...  No Finding  val_train_split  \\\n",
       " 15                        0.143000  ...           0                1   \n",
       " 43                        0.143000  ...           0                1   \n",
       " 50                        0.143000  ...           0                1   \n",
       " 73                        0.143000  ...           0                1   \n",
       " 93                        0.143000  ...           0                1   \n",
       " ...                            ...  ...         ...              ...   \n",
       " 42227                     0.143000  ...           0                1   \n",
       " 42243                     0.143000  ...           0                1   \n",
       " 42293                     0.194311  ...           0                1   \n",
       " 42312                     0.143000  ...           0                1   \n",
       " 42321                     0.143000  ...           0                1   \n",
       " \n",
       "        test_split  all_zeros  tube_prob  age_in_years  age_geq_50  \\\n",
       " 15              1          0   0.194765          35.0           0   \n",
       " 43              1          0   0.542098          16.0           0   \n",
       " 50              1          0   0.601653          60.0           1   \n",
       " 73              1          0   0.033746          74.0           1   \n",
       " 93              1          0   0.826267          45.0           0   \n",
       " ...           ...        ...        ...           ...         ...   \n",
       " 42227           1          0   0.017313          65.0           1   \n",
       " 42243           1          0   0.108642          19.0           0   \n",
       " 42293           1          0   0.167859          38.0           0   \n",
       " 42312           1          0   0.987806          56.0           1   \n",
       " 42321           1          0   0.217463          28.0           0   \n",
       " \n",
       "        gender_m0f1  view_pa0_ap1  tube_geq_0p5  \n",
       " 15               1             0             0  \n",
       " 43               0             0             1  \n",
       " 50               0             0             1  \n",
       " 73               1             0             0  \n",
       " 93               1             0             1  \n",
       " ...            ...           ...           ...  \n",
       " 42227            0             0             0  \n",
       " 42243            0             0             0  \n",
       " 42293            0             0             0  \n",
       " 42312            0             0             1  \n",
       " 42321            0             0             0  \n",
       " \n",
       " [2810 rows x 35 columns],\n",
       " 'df_c1_s1':                                                     path  \\\n",
       " 262    /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 298    /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 858    /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 892    /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 1352   /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " ...                                                  ...   \n",
       " 41470  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 41698  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 41994  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42023  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " 42295  /jet/home/nmurali/asc170022p/shared/Data/chest...   \n",
       " \n",
       "                                                  labels  Follow-up #  \\\n",
       " 262        Infiltration|Pleural_Thickening|Pneumothorax            0   \n",
       " 298                                        Pneumothorax            1   \n",
       " 858                                        Pneumothorax            1   \n",
       " 892                                        Pneumothorax            1   \n",
       " 1352                              Effusion|Pneumothorax           54   \n",
       " ...                                                 ...          ...   \n",
       " 41470                                      Pneumothorax            2   \n",
       " 41698  Atelectasis|Consolidation|Emphysema|Pneumothorax            1   \n",
       " 41994                  Infiltration|Nodule|Pneumothorax            2   \n",
       " 42023                Atelectasis|Emphysema|Pneumothorax           17   \n",
       " 42295             Atelectasis|Infiltration|Pneumothorax           33   \n",
       " \n",
       "        patient_id   age gender view  OriginalImage[Width  Height]  \\\n",
       " 262         22141  030Y      M   AP                 2544     3056   \n",
       " 298          2059  047Y      M   AP                 2500     2048   \n",
       " 858            71  069Y      F   AP                 2500     2048   \n",
       " 892          9206  070Y      M   AP                 2500     2048   \n",
       " 1352        25252  030Y      M   AP                 3056     2544   \n",
       " ...           ...   ...    ...  ...                  ...      ...   \n",
       " 41470       29159  051Y      F   AP                 3056     2544   \n",
       " 41698        3052  045Y      F   AP                 2500     2048   \n",
       " 41994       29863  058Y      M   AP                 3056     2544   \n",
       " 42023        6585  016Y      F   AP                 2500     2048   \n",
       " 42295       13111  024Y      M   AP                 3056     2544   \n",
       " \n",
       "        OriginalImagePixelSpacing[x  ...  No Finding  val_train_split  \\\n",
       " 262                          0.139  ...           0                1   \n",
       " 298                          0.168  ...           0                1   \n",
       " 858                          0.168  ...           0                1   \n",
       " 892                          0.168  ...           0                1   \n",
       " 1352                         0.139  ...           0                1   \n",
       " ...                            ...  ...         ...              ...   \n",
       " 41470                        0.139  ...           0                1   \n",
       " 41698                        0.171  ...           0                1   \n",
       " 41994                        0.139  ...           0                1   \n",
       " 42023                        0.168  ...           0                1   \n",
       " 42295                        0.139  ...           0                0   \n",
       " \n",
       "        test_split  all_zeros  tube_prob  age_in_years  age_geq_50  \\\n",
       " 262             1          0   0.001871          30.0           0   \n",
       " 298             1          0   0.175763          47.0           0   \n",
       " 858             1          0   0.008641          69.0           1   \n",
       " 892             1          0   0.001563          70.0           1   \n",
       " 1352            1          0   0.152656          30.0           0   \n",
       " ...           ...        ...        ...           ...         ...   \n",
       " 41470           1          0   0.833086          51.0           1   \n",
       " 41698           1          0   0.192511          45.0           0   \n",
       " 41994           1          0   0.215971          58.0           1   \n",
       " 42023           1          0   0.136424          16.0           0   \n",
       " 42295           1          0   0.036311          24.0           0   \n",
       " \n",
       "        gender_m0f1  view_pa0_ap1  tube_geq_0p5  \n",
       " 262              0             1             0  \n",
       " 298              0             1             0  \n",
       " 858              1             1             0  \n",
       " 892              0             1             0  \n",
       " 1352             0             1             0  \n",
       " ...            ...           ...           ...  \n",
       " 41470            1             1             1  \n",
       " 41698            1             1             0  \n",
       " 41994            0             1             0  \n",
       " 42023            1             1             0  \n",
       " 42295            0             1             0  \n",
       " \n",
       " [121 rows x 35 columns]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Depth Analysis (Get Layer Embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tips:\n",
    "* your csv file over which you compute embeddings let it be 3k samples max\n",
    "* the csv file should be from the same dataset, it could be anything train, val or test, \n",
    "whether model was trained on it or not doesn't matter. as long as its same dataset, the\n",
    "distribution is going to be the same\n",
    "* and lets say you're computing PDs over the age label, then make sure that csv file\n",
    "has balanced age values. Like 50% are 1's and rest are 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: densenet121 model, provide a hook function\n",
    "# output: returns a model with hooks registered for all 58 layers\n",
    "def register_hooks(model, hook):\n",
    "    \n",
    "    for idx,layer in enumerate(model.features.denseblock1):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(model.features.denseblock2):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(model.features.denseblock3):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(model.features.denseblock4):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "def hook_feat_map(mod, inp, out):\n",
    "    feature_maps.append(torch.reshape(out, (out.shape[0],-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user hyperparams\n",
    "imgsize=128\n",
    "model = torch.load('xxx/NIH-densenet121-NIH_128-best-auc1.0000.pt').to('cuda')\n",
    "model = register_hooks(model, hook_feat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class center_crop(object):\n",
    "    def crop_center(self, img):\n",
    "        _, y, x = img.shape\n",
    "        crop_size = np.min([y,x])\n",
    "        startx = x // 2 - (crop_size // 2)\n",
    "        starty = y // 2 - (crop_size // 2)\n",
    "        return img[:, starty:starty + crop_size, startx:startx + crop_size]\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.crop_center(img)\n",
    "\n",
    "class normalize(object):\n",
    "    def normalize_(self, img, maxval=255):\n",
    "        img = (img)/(maxval)\n",
    "        return img\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.normalize_(img)\n",
    "    \n",
    "def to_cpu(arr):\n",
    "    for idx,x in enumerate(arr):\n",
    "        arr[idx] = x.to('cpu')\n",
    "    return arr\n",
    "\n",
    "def print_memory_profile(s):\n",
    "    # print GPU memory\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    print(s)\n",
    "    print(t/1024**3,r/1024**3,a/1024**3)\n",
    "    print('\\n')\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((imgsize,imgsize)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(center_crop()),\n",
    "    torchvision.transforms.Lambda(normalize())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial\n",
      "31.74853515625 0.240234375 0.19818353652954102\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "100%|██████████| 1/1 [00:56<00:00, 56.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing Batch\n",
      "31.74853515625 10.572265625 5.946712017059326\n",
      "\n",
      "\n",
      "After freeing GPU memory\n",
      "31.74853515625 0.109375 0.08733701705932617\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:56<00:00, 56.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# code for saving pkl file of layer embeddings\n",
    "nih_val_csv = 'xxx/age_view_bal.csv'\n",
    "save_path = 'xxx/clfPneumAgeView1p0.pkl'\n",
    "bs = 3072\n",
    "cls_name = 'Pneumothorax'  # labels wrt which you want to do KNN classification\n",
    "\n",
    "dataset = datasets.MIMIC_Dataset(csvpath=nih_val_csv, class_names=[cls_name], transform=transforms)\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=bs,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=4, \n",
    "                                     pin_memory=True)\n",
    "\n",
    "handle = open(save_path, \"wb\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b_idx,batch in enumerate(tqdm(loader)):\n",
    "        \n",
    "        # print GPU memory\n",
    "        print_memory_profile('Initial')\n",
    "        \n",
    "        imgs = batch['img'].to('cuda')\n",
    "        labels = batch['lab']\n",
    "        paths = batch['file_name']\n",
    "        \n",
    "        feature_maps = []\n",
    "        out = model(imgs)\n",
    "        \n",
    "        info_dict = {'batch_idx':b_idx,'num_batches':len(loader),'feats':feature_maps,'labels':labels,'paths':paths}\n",
    "        pickle.dump(info_dict, handle)  \n",
    "        \n",
    "        # print GPU memory\n",
    "        print_memory_profile('After processing Batch')\n",
    "        \n",
    "        # free up GPU memory\n",
    "        del feature_maps, info_dict\n",
    "        torch.cuda.empty_cache()     \n",
    "        \n",
    "        # print GPU memory\n",
    "        print_memory_profile('After freeing GPU memory')\n",
    "        \n",
    "handle.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over checkpoint iterations and get layer embeddings\n",
    "\n",
    "class center_crop(object):\n",
    "    def crop_center(self, img):\n",
    "        _, y, x = img.shape\n",
    "        crop_size = np.min([y,x])\n",
    "        startx = x // 2 - (crop_size // 2)\n",
    "        starty = y // 2 - (crop_size // 2)\n",
    "        return img[:, starty:starty + crop_size, startx:startx + crop_size]\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.crop_center(img)\n",
    "\n",
    "class normalize(object):\n",
    "    def normalize_(self, img, maxval=255):\n",
    "        img = (img)/(maxval)\n",
    "        return img\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.normalize_(img)\n",
    "    \n",
    "def to_cpu(arr):\n",
    "    for idx,x in enumerate(arr):\n",
    "        arr[idx] = x.to('cpu')\n",
    "    return arr\n",
    "\n",
    "def print_memory_profile(s):\n",
    "    # print GPU memory\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    print(s)\n",
    "    print(t/1024**3,r/1024**3,a/1024**3)\n",
    "    print('\\n')\n",
    "\n",
    "iters = [0,205,410,615,820,1025,1230,1435,1640,1845,2050,2255,2460,2665,2870,3075,3280,3485,3690,3895,4100,4305,4510,4715,4920,5125]\n",
    "for i in tqdm(iters):\n",
    "\n",
    "    # input: densenet121 model, provide a hook function\n",
    "    # output: returns a model with hooks registered for all 58 layers\n",
    "    def register_hooks(model, hook):\n",
    "\n",
    "        for idx,layer in enumerate(model.features.denseblock1):\n",
    "            if idx%2==0:\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "        for idx,layer in enumerate(model.features.denseblock2):\n",
    "            if idx%2==0:\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "        for idx,layer in enumerate(model.features.denseblock3):\n",
    "            if idx%2==0:\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "        for idx,layer in enumerate(model.features.denseblock4):\n",
    "            if idx%2==0:\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "        return model\n",
    "\n",
    "    feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "    def hook_feat_map(mod, inp, out):\n",
    "        feature_maps.append(torch.reshape(out, (out.shape[0],-1)))\n",
    "\n",
    "    # user hyperparams\n",
    "    imgsize = 128\n",
    "    model = torch.load(f'xxx/e1-it{i}.pt').to('cuda')\n",
    "    model = register_hooks(model, hook_feat_map)\n",
    "    nih_val_csv = 'xxx/data/nih/train_splits/train_only_pneum_balanced.csv'\n",
    "    save_path = f'xxx/projects/shortcut_detection_and_mitigation/data/nih/layer_embeddings/imgsize_128/nih_shortcut_iterations/ep1-it{i}.pkl'\n",
    "    bs = 3072\n",
    "\n",
    "\n",
    "\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "    #     torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((imgsize,imgsize)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(center_crop()),\n",
    "        torchvision.transforms.Lambda(normalize())\n",
    "    ])\n",
    "\n",
    "    \n",
    "\n",
    "    dataset = datasets.MIMIC_Dataset(csvpath=nih_val_csv, class_names=['Pneumothorax'], transform=transforms)\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=bs,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4, \n",
    "                                         pin_memory=True)\n",
    "\n",
    "    handle = open(save_path, \"wb\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b_idx,batch in enumerate(tqdm(loader)):\n",
    "\n",
    "            # print GPU memory\n",
    "            print_memory_profile('Initial')\n",
    "\n",
    "            imgs = batch['img'].to('cuda')\n",
    "            labels = batch['lab']\n",
    "            paths = batch['file_name']\n",
    "\n",
    "            feature_maps = []\n",
    "            out = model(imgs)\n",
    "\n",
    "            info_dict = {'batch_idx':b_idx,'num_batches':len(loader),'feats':feature_maps,'labels':labels,'paths':paths}\n",
    "            pickle.dump(info_dict, handle)  \n",
    "\n",
    "            # print GPU memory\n",
    "            print_memory_profile('After processing Batch')\n",
    "\n",
    "            # free up GPU memory\n",
    "            del feature_maps, info_dict\n",
    "            torch.cuda.empty_cache()     \n",
    "\n",
    "            # print GPU memory\n",
    "            print_memory_profile('After freeing GPU memory')\n",
    "\n",
    "    handle.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Layer Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to the folder having several iterations of pkl files\n",
    "# create a folder in that dir_path called 'layer_ranks' where your ranks\n",
    "# for the layers are stored as pkl files containing lists of integer ranks for each layer\n",
    "# with the same name as the pickle file\n",
    "dir_path = '/xxx/shortcut_detection_and_mitigation/data/nih/layer_embeddings/imgsize_128/nih_spurious_iterations'\n",
    "for filename in tqdm(os.listdir(dir_path)):\n",
    "    \n",
    "    pkl_path = os.path.join(dir_path,filename)\n",
    "    ranks = []\n",
    "    \n",
    "    with open(pkl_path, 'rb') as handle:\n",
    "        info_dict = pickle.load(handle)\n",
    "        for feat in tqdm(info_dict['feats']):\n",
    "            ranks.append(int(torch.linalg.matrix_rank(feat)))\n",
    "    \n",
    "    with open(os.path.join(dir_path,'layer_ranks',filename), 'wb') as handle:\n",
    "        pickle.dump(ranks, handle)\n",
    "        \n",
    "    # free GPU memory\n",
    "    del feat, info_dict\n",
    "    torch.cuda.empty_cache()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_idx', 'num_batches', 'feats', 'labels', 'paths'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15070485c4c0>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# for feat in info_dict['feats']:\n",
    "#     y.append(feat.shape[1])\n",
    "\n",
    "x = range(4,120,4)\n",
    "y = [98304,163840,229376,40960,57344,73728,90112,106496,122880,18432,22528,26624,30720,34816,38912,43008,47104,51200,55296,59392,63488,8704,9728,10752,11776,12800,13824,14848,15872]\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98304,\n",
       " 163840,\n",
       " 229376,\n",
       " 40960,\n",
       " 57344,\n",
       " 73728,\n",
       " 90112,\n",
       " 106496,\n",
       " 122880,\n",
       " 18432,\n",
       " 22528,\n",
       " 26624,\n",
       " 30720,\n",
       " 34816,\n",
       " 38912,\n",
       " 43008,\n",
       " 47104,\n",
       " 51200,\n",
       " 55296,\n",
       " 59392,\n",
       " 63488,\n",
       " 8704,\n",
       " 9728,\n",
       " 10752,\n",
       " 11776,\n",
       " 12800,\n",
       " 13824,\n",
       " 14848,\n",
       " 15872]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run KNN to get PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs a (1) array of KNN clf decision for various layers\n",
    "# (2) pred depth of the image\n",
    "# def compute_pred_depth(img, model, layer_embs_path, dataset='NIH'):\n",
    "#     pass\n",
    "\n",
    "def compute_pred_depth(arr):\n",
    "    last = arr[-1]\n",
    "    p_depth = 4\n",
    "    for i in range(len(arr)-1):\n",
    "        ele = arr[-1-(i+1)]\n",
    "        if ele!=last:\n",
    "            p_depth = (len(arr)-(i+1))*4 + 4\n",
    "            break\n",
    "    \n",
    "    return p_depth\n",
    "\n",
    "# plots a \n",
    "def plot_pd_distr(df, model, layer_embs_path, csv=None, dataset='NIH'):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run compute_pd.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PD Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([62.]), array([-0.5,  0.5]), <BarContainer object of 1 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAG5CAYAAAAUFpQ9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfqUlEQVR4nO3dfbRddX3n8fcHEKo8FJBAMUCDFqlo22hTxKFaKhbBoaK2WhBZqWKDXTBqLVXAjk9TZ9oahVqrTiwIVuVBkYoUK5RW0bYoAQGBQAXlIRKTICqoDBr4zh9nR36Ge5ObkH3Ovfe8X2uddff57b3P/v5uLufDbz+mqpAkSQNbjLoASZKmE4NRkqSGwShJUsNglCSpYTBKktQwGCVJahiM0hAkqSS/NITtHJfktG56Xrfdraaw3kFJlm/iNjd53U21ubaZZJskNyXZdXPUpdnBYNTIJbktycok2zZtr07y+eb9T4MlyduSfHSCzxlW+Pxhki/1vZ2NlWRr4M+Bd426lqno/t3nddNnJvmLIW33oLV/W1X1AHAG8KZhbFszg8Go6WIr4HWjLmKGOwK4qaq+NepCZpiPAwuTbDPqQjQ9GIyaLt4FnJhkxz4+vNmtuDDJHUnuTvLmZv42SU5Lclf3Om2iL8okTwE+CDwryQ+SfK9r/3ySVzfLTTSqfEGSb3TbfleSLZrlX5VkWZLvJvlckl/s2pPk1CSrknw/yXVJnjZJNw8DvrCe38Eru23c19Vx3ATLnNLVd1uSo9f5/Szufncrk3wwyWMn29bGSLIIOBp4Y/c7/UzX/jN7ACYaVW6OeqtqOfBd4IDN0R/NfAajpoulwOeBE3vezm8C+wIHA2/pgg7gzQy+GOcDvwbsz2C35M+oqmXAa4D/rKrtqmrHjdj2i4EFwDMYjO5eBZDkRcApwEuAOcAXgbO7dQ4BngM8GdgR+APgO5N8/q8AN69n+6uAw4EdgFcCpyZ5RjP/F4BdgLnAQmBJkn27eX/V1TAf+KVumbdMtJEkFyX53iSvi9YuV1Xzquq2qloCfAz46+53+rvr6UNrk+qtqs9X1UHrfNYyBv/uksGoaeUtwP9IMmcKy75s3S/dKW7j7VV1f1VdC1zLw1+GRwPvqKpVVbUaeDtwzMZ2YAP+qqruqao7gNOAo7r244D/U1XLqmoN8L+B+d2o8SfA9sAvA+mWWTHJ5+8I3DfZxqvqn6rq1hr4AnAJ8Ox1FvufVfVAN/+fGPyeA/wR8Cdd/fd1NR45yXYOr6odJ3kdvoHf0cZ61PV27mPw+5PY4Nlq0rBU1fXdiOIkBv8Hvz7nVdUr2oYk1Uz/oJm1XzP97Wb6R8B23fQTgNubebd3bZvTnZN8/i8Cf5Pk3c38AHOr6l+TvA/4O2CvJBcAJ1bVvRN8/ncZhOiEkhwGvJXBSGoL4HHA19r1q+qHE9Q4p1v2qkHm/LS+LdfT12HYnPVuD3yvhxo1Azli1HTzVgb/tz/30XxIt0tu7euOKaxyF4OAWmuvrm3Cj5+g7YcMvozX+oUJltlzks+/EzhunZHVY6vqP7q+vLeqfh14KoNQ+7NJ6rqum/8I3fHS84HFwG7dLuCLGQTGWju1ZwY3Nd4N3A88tanv56tqOyaQ5LPdscKJXp+dpPaJfqc/Yv2/081Sb+cpDPYgSAajppequgU4F3jtkDd9NvDnSeYk2YXBbt1HXBLSWQns0V0esdY1wEuSPK47YeTYCdb7syQ7JdmTwRm453btHwROTvJUgCQ/n+Sl3fRvJHlmkscwCN//Bzw4SV0XA781ybytgW2A1cCabvR4yATLvT3J1kmezeB45Ceq6iHgQwyOSe7a1TU3yfMn2lBVHbbO/5i0r8MmqW8l8MR12q4BXp5kyySHTtK3R11vkrnAzsAVk9SmMWMwajp6B7DtBpfavP6CwQlA1zHYvXh11zaRfwVuAL6d5O6u7VTgxwy+4M9icDLJuj4NXMXgC/+fgNMBquoCBieLnJPkXuB6BmeYwuBEmQ8x2E16O4MTbxZPUtdngF9O8ohdwN1xttcC53Wf9XLgwnUW+3Y3766u/tdU1U3dvDcBtwBXdDX+C4OTmDaX04H9uuPF/9i1vQ74XQa7OI8G/nGddTZXvS8HzuquaZSIDyqWZo/u0of9qur1o65lJuh2MV8LPKeqVo26Hk0PBqMkSQ13pUqS1DAYJUlqGIySJDVm9AX+u+yyS82bN2/UZUiSppGrrrrq7qqayh20JjSjg3HevHksXbp01GVIkqaRJLdveKnJuStVkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1egvGJHsm+bcky5LckOR1XfvOSS5N8vXu507NOicnuSXJzZM9IkaSpD71OWJcA/xpVT0FOAA4Psl+DJ7OfllV7QNc1r2nm3ckg4exHgq8P8monxAuSRozvQVjVa2oqqu76fuAZQyeyn4Eg+fV0f18UTd9BHBOVT1QVd9k8Cy1/fuqT5KkiQzlGGOSecDTgS8Du1XVChiEJ7Brt9hc4M5mteVd27qftSjJ0iRLV69e3WvdkqTx03swJtkOOB94fVXdu75FJ2h7xMMiq2pJVS2oqgVz5mzyrfAkSZpQr8GY5DEMQvFjVfWprnllkt27+bsDa5+avRzYs1l9D+CuPuuTJGldfZ6VGuB0YFlVvaeZdSGwsJteCHy6aT8yyTZJ9gb2Ab7SV32SJE2kz6drHAgcA3wtyTVd2ynAXwLnJTkWuAN4KUBV3ZDkPOBGBme0Hl9VD/ZYnyRJj9BbMFbVl5j4uCHAwZOs807gnX3VJEnShnjnG0mSGjP6QcWSNAonXnLilJddfMjiHitRHxwxSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNXoLxiRnJFmV5Pqm7dwk13Sv25Jc07XPS3J/M++DfdUlSdL6bNXjZ58JvA/4yNqGqvqDtdNJ3g18v1n+1qqa32M9kiRtUG/BWFWXJ5k30bwkAV4GPLev7UuStClGdYzx2cDKqvp607Z3kq8m+UKSZ0+2YpJFSZYmWbp69er+K5UkjZVRBeNRwNnN+xXAXlX1dOANwMeT7DDRilW1pKoWVNWCOXPmDKFUSdI4GXowJtkKeAlw7tq2qnqgqr7TTV8F3Ao8edi1SZI0ihHj84Cbqmr52oYkc5Js2U0/EdgH+MYIapMkjbk+L9c4G/hPYN8ky5Mc2806kp/djQrwHOC6JNcCnwReU1X39FWbJEmT6fOs1KMmaf/DCdrOB87vqxZJkqbKO99IktQwGCVJahiMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhoGoyRJjd6CMckZSVYlub5pe1uSbyW5pnu9oJl3cpJbktyc5Pl91SVJ0vr0OWI8Ezh0gvZTq2p+97oYIMl+wJHAU7t13p9kyx5rkyRpQr0FY1VdDtwzxcWPAM6pqgeq6pvALcD+fdUmSdJkRnGM8YQk13W7Wnfq2uYCdzbLLO/aHiHJoiRLkyxdvXp137VKksbMsIPxA8CTgPnACuDdXXsmWLYm+oCqWlJVC6pqwZw5c3opUpI0voYajFW1sqoerKqHgA/x8O7S5cCezaJ7AHcNszZJkmDIwZhk9+bti4G1Z6xeCByZZJskewP7AF8ZZm2SJAFs1dcHJzkbOAjYJcly4K3AQUnmM9hNehtwHEBV3ZDkPOBGYA1wfFU92FdtkiRNprdgrKqjJmg+fT3LvxN4Z1/1SJI0Fd75RpKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNXoLxiRnJFmV5Pqm7V1JbkpyXZILkuzYtc9Lcn+Sa7rXB/uqS5Kk9elzxHgmcOg6bZcCT6uqXwX+Czi5mXdrVc3vXq/psS5JkibVWzBW1eXAPeu0XVJVa7q3VwB79LV9SZI2xSiPMb4K+Gzzfu8kX03yhSTPnmylJIuSLE2ydPXq1f1XKUkaKyMJxiRvBtYAH+uaVgB7VdXTgTcAH0+yw0TrVtWSqlpQVQvmzJkznIIlSWNj6MGYZCFwOHB0VRVAVT1QVd/ppq8CbgWePOzaJEkaajAmORR4E/DCqvpR0z4nyZbd9BOBfYBvDLM2SZIAturrg5OcDRwE7JJkOfBWBmehbgNcmgTgiu4M1OcA70iyBngQeE1V3TPhB0uS1KPegrGqjpqg+fRJlj0fOL+vWiRJmirvfCNJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhobFYxJtpjsVm2SJM0GGwzGJB9PskOSbYEbgZuT/Fn/pUmSNHxTGTHuV1X3Ai8CLgb2Ao7psyhJkkZlKsH4mCSPYRCMn66qnwDVa1WSJI3IVILx/wK3AdsClyf5ReDePouSJGlUNniv1Kp6L/Depun2JL/dX0mSJI3OVE6+2S3J6Uk+273fD1jYe2WSJI3AVHalngl8DnhC9/6/gNf3VI8kSSM1lWDcparOAx4CqKq1z0yUJGnWmUow/jDJ4+nORE1yAPD9XquSJGlEpvKg4jcAFwJPSvLvwBzg93utSpKkEZnKWalXJ/ktYF8gwM3dtYySJM06GwzGJC9Zp+nJSb4PfK2qVvVTliRJozGVXanHAs8C/q17fxBwBYOAfEdV/UNPtUmSNHRTCcaHgKdU1UoYXNcIfAB4JnA5YDBKkmaNqZyVOm9tKHZWAU+uqnsAjzVKkmaVqYwYv5jkIuAT3fvfY3DP1G2B7/VVmCRJozCVYDyeQRgeyOCs1I8A51dVAd4zVZI0q0zlco0CPtm9JEma1aZyE/EDklyZ5AdJfpzkwSQ+dkqSNCtN5eSb9wFHAV8HHgu8GvjbPouSJGlUpnKMkaq6JcmWVfUg8OEk/9FzXZIkjcRUgvFHSbYGrkny18AKYNt+y5IkaTSmsiv1GGBL4ATgh8CeDM5SlSRp1pnKWam3d5P3A2/vtxxJkkZrKmelHp7kq0nuSXJvkvs8K1WSNFtN5RjjacBLGDxNo/otR5Kk0ZrKMcY7gesNRUnSOJjKiPGNwMVJvgA8sLaxqt7TW1WSJI3IVILxncAPgJ8Dtu63HEmSRmsqwbhzVR3SeyWSJE0DUznG+C9JNjoYk5yRZFWS65u2nZNcmuTr3c+dmnknJ7klyc1Jnr+x25MkaXOYSjAeD/xzkvs38nKNM4FD12k7CbisqvYBLuvek2Q/4Ejgqd0670+y5RT7IEnSZrPBYKyq7atqi6p6bFXt0L3fYQrrXQ7cs07zEcBZ3fRZwIua9nOq6oGq+iZwC7D/VDshSdLmMukxxiTPWN+KVXX1Jmxvt6pa0a2/IsmuXftc4IpmueVd20R1LQIWAey1116bUIIkSZNb38k3717PvAKeuxnryCTbeGRj1RJgCcCCBQu8tlKStFlNGoxV9ds9bG9lkt270eLuwKqufTmDm5OvtQdwVw/blyRpvaZy8s3mdCGwsJteCHy6aT8yyTZJ9gb2Ab4y5NokSZrag4o3RZKzgYOAXZIsB94K/CVwXpJjgTuAlwJU1Q1JzgNuBNYAx3cPRZ5WTrzkxI1afvEhi3uqRJLUl/WdfHNgVf17km2q6oHJlptMVR01yayDJ1n+nQzusiNJ0sisb1fqe7uf/zmMQiRJmg7Wtyv1J0k+DMxN8t51Z1bVa/srS5Kk0VhfMB4OPI/BZRlXDaccSZJGa32Xa9wNnJNkWVVdO8SaJEkamalcrvGdJBd0NwRfmeT8JHv0XpkkSSMwlWD8MIPrDJ/A4DZtn+naJEmadaYSjLtW1Yerak33OhOY03NdkiSNxFSCcXWSVyTZsnu9AvhO34VJkjQKUwnGVwEvA74NrAB+v2uTJGnW2eAt4arqDuCFQ6hFkqSRG/ZNxCVJmtYMRkmSGgajJEmNDQZjkj9vprfptxxJkkZr0mBM8sYkz2JwFupaPmlDkjSrre+s1JsZPEj4iUm+CCwDHp9k36q6eSjVSZI0ZOvblfpd4BTgFuAgHn4+40lJ/qPnuiRJGon1jRgPBd4KPAl4D3At8MOqeuUwCpMkaRQmHTFW1SlVdTBwG/BRBiE6J8mXknxmSPVJkjRUG7zzDfC5qroSuDLJH1fVbybZpe/CJEkahQ1erlFVb2ze/mHXdndfBUmSNEobdYF/VV3bVyGSJE0H3vlGkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhpbDXuDSfYFzm2angi8BdgR+CNgddd+SlVdPNzqJEnjbujBWFU3A/MBkmwJfAu4AHglcGpVLR52TZIkrTXqXakHA7dW1e0jrkOSJGD0wXgkcHbz/oQk1yU5I8lOE62QZFGSpUmWrl69eqJFJEnaZCMLxiRbAy8EPtE1fQB4EoPdrCuAd0+0XlUtqaoFVbVgzpw5wyhVkjRGRjliPAy4uqpWAlTVyqp6sKoeAj4E7D/C2iRJY2qUwXgUzW7UJLs3814MXD/0iiRJY2/oZ6UCJHkc8DvAcU3zXyeZDxRw2zrzJEkaipEEY1X9CHj8Om3HjKIWSZJaoz4rVZKkacVglCSpYTBKktQwGCVJahiMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsNglCSpYTBKktQwGCVJahiMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsNglCSpsdWoCxiFE0/82feLF4+mDknS9OOIUZKkhsEoSVLDYJQkqWEwSpLUMBglSWoYjJIkNQxGSZIaY3kdoyRNVydecuKGF+osPsSLsPvgiFGSpIbBKElSw12pktSjjdk1qunBEaMkSQ1HjBorntggaUMcMUqS1DAYJUlqGIySJDUMRkmSGgajJEmNkZyVmuQ24D7gQWBNVS1IsjNwLjAPuA14WVV9dxT1SZLG1yhHjL9dVfOrakH3/iTgsqraB7isey9J0lBNp12pRwBnddNnAS8aXSmSpHE1qmAs4JIkVyVZ1LXtVlUrALqfu060YpJFSZYmWbp69eohlStJGhejuvPNgVV1V5JdgUuT3DTVFatqCbAEYMGCBdVXgZKk8TSSEWNV3dX9XAVcAOwPrEyyO0D3c9UoapMkjbehB2OSbZNsv3YaOAS4HrgQWNgtthD49LBrkyRpFLtSdwMuSLJ2+x+vqn9OciVwXpJjgTuAl46gNknSmBt6MFbVN4Bfm6D9O8DBw65HkqTWdLpcQ5KkkTMYJUlqGIySJDUMRkmSGgajJEkNg1GSpIbBKElSw2CUJKlhMEqS1DAYJUlqGIySJDUMRkmSGgajJEkNg1GSpIbBKElSw2CUJKlhMEqS1DAYJUlqGIySJDUMRkmSGgajJEkNg1GSpIbBKElSw2CUJKlhMEqS1DAYJUlqGIySJDUMRkmSGgajJEkNg1GSpIbBKElSw2CUJKlhMEqS1Nhq1AVI09WJl5w45WUXH7K4x0okDZMjRkmSGgajJEkNg1GSpMbQjzEm2RP4CPALwEPAkqr6myRvA/4IWN0tekpVXTzs+iTNHh4n1qYYxck3a4A/raqrk2wPXJXk0m7eqVXlX6ckaWSGHoxVtQJY0U3fl2QZMHfYdUiSNJGRHmNMMg94OvDlrumEJNclOSPJTqOrTJI0rkZ2HWOS7YDzgddX1b1JPgD8L6C6n+8GXjXBeouARQB77bXX8AqWpGnGY6j9GEkwJnkMg1D8WFV9CqCqVjbzPwRcNNG6VbUEWAKwYMGC6r9aafPzC02avoa+KzVJgNOBZVX1nqZ992axFwPXD7s2SZJGMWI8EDgG+FqSa7q2U4CjksxnsCv1NuC4EdQmSRpzozgr9UtAJpjlNYuSpJHzJuLSLOKxS+nR85ZwkiQ1HDFKmpLpMBrdmBqkTeWIUZKkhsEoSVLDYJQkqeExRkmb3XQ4HrmxPH6ptRwxSpLUcMQoSWNgJo7iR8VglKSNdPiSz0952YsWHdRbHeqHu1IlSWo4YpSmub5OCvFkE01mY/82ZtuuV0eMkiQ1DEZJkhoGoyRJDYNRkqSGwShJUsOzUjfCxly7BMAhvZTRKy8CljTuHDFKktRwxDgDOaqTNJ3Mtu8kg7FH0+GPxYu4h8PfszR7uCtVkqSGwShJUsNglCSp4TFGDUWfx+BmwsF8qQ8+/qofjhglSWo4YpSkMeDocuocMUqS1HDEOE3MxOvgZmLN0rBt7K0kx320Nh04YpQkqeGIUZLYhIcEaNZyxChJUsMRo8aKZ+ZJ2hCDUZKmkemwS7fXGmbAc2rdlSpJUsMR4wzk7kBJ6o8jRkmSGo4YezQdRnYz8eLijT6+MQOOWaxrtv9tbNRnz8B/P81u027EmOTQJDcnuSXJSaOuR5I0XqbViDHJlsDfAb8DLAeuTHJhVd042sr6Nx3ORNtYM7HmjTEdRnUztY7ZXINmv+k2YtwfuKWqvlFVPwbOAY4YcU2SpDGSqhp1DT+V5PeBQ6vq1d37Y4BnVtUJzTKLgEXd232Bmx/FJncB7n4U689U49pvGN++j2u/YXz7Pq79Bti3qrbf1JWn1a5UIBO0/UxyV9USYMlm2ViytKoWbI7PmknGtd8wvn0f137D+PZ9XPsNg74/mvWn267U5cCezfs9gLtGVIskaQxNt2C8Etgnyd5JtgaOBC4ccU2SpDEyrXalVtWaJCcAnwO2BM6oqht63ORm2SU7A41rv2F8+z6u/Ybx7fu49hseZd+n1ck3kiSN2nTblSpJ0kgZjJIkNcYyGMfptnNJ9kzyb0mWJbkhyeu69p2TXJrk693PnUZdax+SbJnkq0ku6t6PS793TPLJJDd1//bPGoe+J/mT7u/8+iRnJ/m52drvJGckWZXk+qZt0r4mObn7zrs5yfNHU/WjN0m/39X9rV+X5IIkOzbzNrrfYxeMzW3nDgP2A45Kst9oq+rVGuBPq+opwAHA8V1/TwIuq6p9gMu697PR64Blzftx6fffAP9cVb8M/BqD38Gs7nuSucBrgQVV9TQGJ/Adyezt95nAoeu0TdjX7r/5I4Gnduu8v/sunInO5JH9vhR4WlX9KvBfwMmw6f0eu2BkzG47V1Urqurqbvo+Bl+Qcxn0+axusbOAF42kwB4l2QP478DfN83j0O8dgOcApwNU1Y+r6nuMQd8ZnGn/2CRbAY9jcB30rOx3VV0O3LNO82R9PQI4p6oeqKpvArcw+C6ccSbqd1VdUlVrurdXMLgGHjax3+MYjHOBO5v3y7u2WS/JPODpwJeB3apqBQzCE9h1hKX15TTgjcBDTds49PuJwGrgw91u5L9Psi2zvO9V9S1gMXAHsAL4flVdwizv9zom6+s4fe+9CvhsN71J/R7HYNzgbedmoyTbAecDr6+qe0ddT9+SHA6sqqqrRl3LCGwFPAP4QFU9Hfghs2f34aS642lHAHsDTwC2TfKK0VY1bYzF916SNzM4fPSxtU0TLLbBfo9jMI7dbeeSPIZBKH6sqj7VNa9Msns3f3dg1ajq68mBwAuT3MZgd/lzk3yU2d9vGPyNL6+qL3fvP8kgKGd7358HfLOqVlfVT4BPAf+N2d/v1mR9nfXfe0kWAocDR9fDF+hvUr/HMRjH6rZzScLgWNOyqnpPM+tCYGE3vRD49LBr61NVnVxVe1TVPAb/xv9aVa9glvcboKq+DdyZZN+u6WDgRmZ/3+8ADkjyuO7v/mAGx9Rne79bk/X1QuDIJNsk2RvYB/jKCOrrRZJDgTcBL6yqHzWzNq3fVTV2L+AFDM5cuhV486jr6bmvv8lg18F1wDXd6wXA4xmctfb17ufOo661x9/BQcBF3fRY9BuYDyzt/t3/EdhpHPoOvB24Cbge+Adgm9nab+BsBsdSf8JgZHTs+voKvLn7zrsZOGzU9W/mft/C4Fji2u+4Dz6afntLOEmSGuO4K1WSpEkZjJIkNQxGSZIaBqMkSQ2DUZKkhsEoTUNJfjDqGqRxZTBKY6y72bakhsEozRBJfjfJl7sbg/9Lkt2SbNE9e29Ot8wW3bPndkkyJ8n5Sa7sXgd2y7wtyZIklwAfGWmnpGnIYJRmji8BB9TgxuDnAG+sqoeAjwJHd8s8D7i2qu5m8EzGU6vqN4Df42cfv/XrwBFV9fKhVS/NEO5GkWaOPYBzu5tDbw18s2s/g8E9MU9j8MidD3ftzwP2G9w2FIAdkmzfTV9YVfcPo2hppnHEKM0cfwu8r6p+BTgO+DmAqrqTwVMVngs8k4efRbcF8Kyqmt+95tbgYdUweBSVpAkYjNLM8fPAt7rphevM+3sGu1TPq6oHu7ZLgBPWLpBkft8FSrOBwShNT49Lsrx5vQF4G/CJJF8E7l5n+QuB7Xh4NyrAa4EFSa5LciPwmmEULs10Pl1DmgWSLGBwos2zR12LNNN58o00wyU5CfhjHj4zVdKj4IhRkqSGxxglSWoYjJIkNQxGSZIaBqMkSQ2DUZKkxv8H886ixY7zA+kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot PDs histogram\n",
    "with open('/home/xxx/shortcut_detection_and_mitigation/experiments/medical_expts/nih/128/nih_test_pd.pkl', 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "\n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "\n",
    "pred_cls = (batch_info['preds']>0.5).astype(int)\n",
    "correct_preds_arr = (pred_cls==batch_info['labels'])\n",
    "pos_pd_arr = (batch_info['pd']>=0)\n",
    "batch_info['pd'][~pos_pd_arr] = 0\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "# plt.subplot(1,2,1)\n",
    "plt.title(\"NIH-no tubes (label='tube')\")\n",
    "plt.ylabel('# of Images')\n",
    "plt.xlabel('Layer')\n",
    "plt.xlim((-5,120))\n",
    "plt.hist(batch_info['pd'][correct_preds_arr & pos_pd_arr],bins=30,color='g',alpha=0.55)\n",
    "plt.hist(batch_info['pd'][~correct_preds_arr & pos_pd_arr],bins=30,color='r',alpha=0.55)\n",
    "plt.hist(batch_info['pd'][~pos_pd_arr],bins=1,color='b',alpha=0.55)\n",
    "# plt.subplot(1,2,2)\n",
    "# # plt.hist(batch_info['pd'][~pos_pd_arr],bins=30,color='b',alpha=0.55)\n",
    "# plt.xlim((-5,5))\n",
    "# plt.bar(0,len(batch_info['pd'][~pos_pd_arr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PDs combined histogram of all groups\n",
    "\n",
    "with open('/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_shortcut_l1_pos_tube_v3.pkl', 'rb') as handle:\n",
    "    batch_info1 = pickle.load(handle)\n",
    "with open('/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_shortcut_l1_pos_notube_v3.pkl', 'rb') as handle:\n",
    "    batch_info2 = pickle.load(handle)\n",
    "with open('/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_shortcut_l1_neg_tube_v3.pkl', 'rb') as handle:\n",
    "    batch_info3 = pickle.load(handle)\n",
    "with open('/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_shortcut_l1_neg_notube_v3.pkl', 'rb') as handle:\n",
    "    batch_info4 = pickle.load(handle)\n",
    "\n",
    "batch_info['pd'] = batch_info1['pd'] + batch_info2['pd'] + batch_info3['pd'] + batch_info4['pd']\n",
    "batch_info['labels'] = batch_info1['labels'] + batch_info2['labels'] + batch_info3['labels'] + batch_info4['labels']\n",
    "batch_info['preds'] = batch_info1['preds'] + batch_info2['preds'] + batch_info3['preds'] + batch_info4['preds']\n",
    "    \n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "\n",
    "pred_cls = (batch_info['preds']>0.5).astype(int)\n",
    "correct_preds_arr = (pred_cls==batch_info['labels'])\n",
    "pos_pd_arr = (batch_info['pd']>=0)\n",
    "\n",
    "plt.title('Prediction Depths on Full Test Data (NIH-shortcut correlation)')\n",
    "plt.ylabel('# of Images')\n",
    "plt.xlabel('Layer')\n",
    "# plt.ylim((0,60))\n",
    "# plt.hist(batch_info['pd'][correct_preds_arr & pos_pd_arr],bins=30,color='g',alpha=0.55)\n",
    "plt.hist(batch_info['pd'][~correct_preds_arr & pos_pd_arr],bins=30,color='r',alpha=0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PD across iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(25):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # plot PDs histogram\n",
    "    with open(f'/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_shortcut_iterations/train_2k_ep{ep+1}.pkl', 'rb') as handle:\n",
    "        batch_info = pickle.load(handle)\n",
    "\n",
    "    batch_info['pd'] = np.array(batch_info['pd'])\n",
    "    batch_info['labels'] = np.array(batch_info['labels'])\n",
    "    batch_info['preds'] = np.array(batch_info['preds'])\n",
    "\n",
    "    pred_cls = (batch_info['preds']>0.5).astype(int)\n",
    "    correct_preds_arr = (pred_cls==batch_info['labels'])\n",
    "    pos_pd_arr = (batch_info['pd']>=0)\n",
    "\n",
    "    plt.figure(ep)\n",
    "    plt.title(f'Prediction Depths (Epoch:{ep+1})')\n",
    "    plt.ylabel('# of Images')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylim((0,550))\n",
    "    plt.hist(batch_info['pd'][correct_preds_arr & pos_pd_arr],bins=30,color='g',alpha=0.55)\n",
    "    plt.hist(batch_info['pd'][~correct_preds_arr & pos_pd_arr],bins=30,color='r',alpha=0.55)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'Ep{ep+1} exec time: {end-start} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse images belonging to certain range of PDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_cls = (batch_info['preds']>0.5).astype(int)\n",
    "\n",
    "crit1 = (pred_cls==batch_info['labels'])\n",
    "crit2 = (batch_info['pd']>80)\n",
    "crit3 = (batch_info['pd']<100)\n",
    "# crit4 = (batch_info['labels']==1) # analyse only images with pneum\n",
    "\n",
    "img_list = np.array(batch_info['paths'])[crit1 & crit2 & crit3].tolist()\n",
    "plot_images(img_list,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Predictions Across Layers for Single Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = '/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_shortcut_l1_pos_notube_v3.pkl'\n",
    "with open(pkl_path, 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "\n",
    "crit1 = (np.array(batch_info['pd'])>=80)\n",
    "crit2 = (np.array(batch_info['pd'])<100)\n",
    "pred_cls = (np.array(batch_info['preds'])>0.5).astype(int)\n",
    "crit3 = (pred_cls==batch_info['labels'])\n",
    "final_arr = np.array(batch_info['layers_knn_mean'])[crit1 & crit2 & ~crit3]\n",
    "# from random import random\n",
    "# r_idx = int(random()*23)\n",
    "\n",
    "for index,y in enumerate(final_arr):\n",
    "    y = np.where(y==99, 0.5, y)\n",
    "    x = range(0,116,4)\n",
    "    plt.figure(index)\n",
    "    plt.plot(x,y)\n",
    "    plt.ylim((-0.1,1.1))\n",
    "    plt.title('KNN Prediction Across Layers for Single Test Image')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('KNN Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tube Detector on PD bins of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:02<00:00, 37.12it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "tube_detector_path = '/xxx/augmentation_by_explanation_eccv22/Output/MIMIC-CXR/tube_detector/MIMIC-CXR-densenet121-MIMIC-CXR_512-best-auc0.8580.pt'  # MIMIC tube detector\n",
    "pkl_file = '/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_shortcut/nih_shortcut_train_data_2k.pkl'  # pd analysis pkl file\n",
    "# process pickle file\n",
    "with open(pkl_file, 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "    \n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['paths'] = np.array(batch_info['paths'])\n",
    "pred_cls = (np.array(batch_info['preds'])>0.5).astype(int)\n",
    "\n",
    "crit1 = (pred_cls==batch_info['labels'])\n",
    "crit2 = (batch_info['pd']==40)\n",
    "crit3 = (batch_info['labels']==1)\n",
    "\n",
    "img_list = batch_info['paths'][crit3 & crit2 ].tolist()\n",
    "\n",
    "# load model\n",
    "model = torch.load(tube_detector_path).to('cuda')\n",
    "\n",
    "\n",
    "# --------------------- Class Definitions ---------------------\n",
    "\n",
    "class center_crop(object):\n",
    "    def crop_center(self, img):\n",
    "        _, y, x = img.shape\n",
    "        crop_size = np.min([y,x])\n",
    "        startx = x // 2 - (crop_size // 2)\n",
    "        starty = y // 2 - (crop_size // 2)\n",
    "        return img[:, starty:starty + crop_size, startx:startx + crop_size]\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.crop_center(img)\n",
    "\n",
    "class normalize(object):\n",
    "    def normalize_(self, img, maxval=255):\n",
    "        img = (img)/(maxval)\n",
    "        return img\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.normalize_(img)\n",
    "\n",
    "# transforms for NIH\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((128,128)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(center_crop()),\n",
    "    torchvision.transforms.Lambda(normalize())\n",
    "])\n",
    "    \n",
    "# loop over chosen set of images and compute model preds\n",
    "preds = []\n",
    "for img_path in tqdm(img_list):\n",
    "    with Image.open(img_path) as img:\n",
    "        with torch.no_grad():\n",
    "            img = transforms(img).unsqueeze(0).to('cuda')\n",
    "            if img.shape[1]==4:\n",
    "                img = img[:,0,:,:].unsqueeze(0)\n",
    "            out = float(torch.sigmoid(model(img)).squeeze())\n",
    "            preds.append(out)\n",
    "         \n",
    "plt.figure(figsize=(7,7))\n",
    "fig = sns.histplot(preds,bins=15)\n",
    "plt.xlabel('Chest Drain Probability',fontsize=20)\n",
    "plt.ylabel('No. of Images',fontsize=20)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "fig.figure.savefig(\"/xxx/shortcut_detection_and_mitigation/experiments/paper_quality_plots/results/layer40_pos_hist.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute PD of a peak of interest using another classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a suitable test_csv file for the peak of interest\n",
    "\n",
    "# user hyperparams\n",
    "pkl_file = '/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/nih_spurious_iterations/age_1p0_train_2k_ep10.pkl'\n",
    "pd_val = 88\n",
    "save_path = '/xxx/shortcut_detection_and_mitigation/data/nih/pd_analysis/imgsize_128/temp/nih_spurious_age_pd88_red.csv'\n",
    "cls_name = 'Pneumothorax'\n",
    "# just verify the mask_arr is what you want\n",
    "\n",
    "with open(pkl_file, 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "    \n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "batch_info['paths'] = np.array(batch_info['paths'])\n",
    "\n",
    "pred_cls = (batch_info['preds']>0.5).astype(int)\n",
    "correct_preds_arr = (pred_cls==batch_info['labels'])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "mask_arr = ( (batch_info['pd']==pd_val) & ~correct_preds_arr )\n",
    "df['path'] = batch_info['paths'][mask_arr]\n",
    "df[cls_name] = batch_info['labels'][mask_arr]\n",
    "\n",
    "df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run compute_pd.py on this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMD Analysis (Get Layer Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: densenet121 model, provide a hook function\n",
    "# output: returns a model with hooks registered for all 58 layers\n",
    "def register_hooks(model, hook):\n",
    "    \n",
    "    for idx,layer in enumerate(model.features.denseblock1):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(model.features.denseblock2):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(model.features.denseblock3):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(model.features.denseblock4):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    return model\n",
    "\n",
    "feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "def hook_feat_map(mod, inp, out):\n",
    "    feature_maps.append(torch.reshape(out, (out.shape[0],-1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user hyperparams\n",
    "imgsize=128\n",
    "model = torch.load('/xxxprojects/augmentation_by_explanation_eccv22/Output/NIH/imgsize_128/nih_pneum/NIH-densenet121-NIH_128-best-auc0.8326.pt').to('cuda')\n",
    "model = register_hooks(model, hook_feat_map)\n",
    "\n",
    "class center_crop(object):\n",
    "    def crop_center(self, img):\n",
    "        _, y, x = img.shape\n",
    "        crop_size = np.min([y,x])\n",
    "        startx = x // 2 - (crop_size // 2)\n",
    "        starty = y // 2 - (crop_size // 2)\n",
    "        return img[:, starty:starty + crop_size, startx:startx + crop_size]\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.crop_center(img)\n",
    "\n",
    "class normalize(object):\n",
    "    def normalize_(self, img, maxval=255):\n",
    "        img = (img)/(maxval)\n",
    "        return img\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.normalize_(img)\n",
    "    \n",
    "def to_cpu(arr):\n",
    "    for idx,x in enumerate(arr):\n",
    "        arr[idx] = x.to('cpu')\n",
    "    return arr\n",
    "\n",
    "def print_memory_profile(s):\n",
    "    # print GPU memory\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    print(s)\n",
    "    print(t/1024**3,r/1024**3,a/1024**3)\n",
    "    print('\\n')\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((imgsize,imgsize)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(center_crop()),\n",
    "    torchvision.transforms.Lambda(normalize())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for saving pkl file of layer embeddings\n",
    "nih_val_csv = '/xxx/data/nih/test_split2/full_splits/pneum_neg_tube.csv'\n",
    "save_path = '/xxx/projects/shortcut_detection_and_mitigation/data/nih/layer_embeddings/imgsize_128/mmd_analysis/test_split2_neg_tube/'\n",
    "cls_name = 'Pneumothorax'\n",
    "\n",
    "dataset = datasets.MIMIC_Dataset(csvpath=nih_val_csv, class_names=[cls_name], transform=transforms)\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=4096,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=4, \n",
    "                                     pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b_idx,batch in enumerate(tqdm(loader)):\n",
    "        # print GPU memory\n",
    "        print_memory_profile('Initial')\n",
    "\n",
    "        imgs = batch['img'].to('cuda')\n",
    "        labels = batch['lab']\n",
    "        paths = batch['file_name']\n",
    "\n",
    "        feature_maps = []\n",
    "        out = model(imgs)\n",
    "\n",
    "        for layer_id in tqdm(range(1000)):\n",
    "            if layer_id==len(feature_maps):\n",
    "                break\n",
    "            handle = open(os.path.join(save_path,'layer-%d.pkl' %(layer_id)), \"ab\")\n",
    "            info_dict = {'batch_idx':b_idx,'num_batches':len(loader),'feats':feature_maps[layer_id],'labels':labels,'paths':paths}\n",
    "            pickle.dump(info_dict, handle)  \n",
    "            handle.close()\n",
    "\n",
    "        # print GPU memory\n",
    "        print_memory_profile('After processing Batch')\n",
    "\n",
    "        # free up GPU memory\n",
    "        del feature_maps, info_dict\n",
    "        torch.cuda.empty_cache()     \n",
    "\n",
    "        # print GPU memory\n",
    "        print_memory_profile('After freeing GPU memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE COMPUTE_MMD.PY FILE TO GENERATE PICKLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MMD curve\n",
    "neg_means = info_pos_tube['neg']['mean']\n",
    "pos_means = info_pos_tube['pos']['mean']\n",
    "\n",
    "Fig, ax = plt.subplots()\n",
    "for i in range(len(pos_means)):\n",
    "    pos_dist = pos_means[i]\n",
    "    neg_dist = neg_means[i]\n",
    "    total = pos_dist + neg_dist\n",
    "    if pos_dist<neg_dist:\n",
    "        color = 'g'\n",
    "        norm_dist = pos_dist/total\n",
    "    elif neg_dist<pos_dist:\n",
    "        color = 'r'\n",
    "        norm_dist = neg_dist/total\n",
    "    else:\n",
    "        color = 'k'\n",
    "        norm_dist = 0.5\n",
    "\n",
    "    ax.plot((i+1)*4, norm_dist, color=color,\n",
    "            marker='o',\n",
    "            linestyle='dashed',\n",
    "            markeredgecolor=color,\n",
    "            markersize=6)\n",
    "    \n",
    "plt.title('MMD Analysis (Neg + No Tube)')\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('Min Dist')\n",
    "ax.set_xlim(0,120)\n",
    "ax.set_ylim(0,1)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new columns by binarizing already present columns\n",
    "df['gender_m0f1'] = df['gender']\n",
    "df['age_geq_50'] = df['age_in_years']\n",
    "df['view_pa0_ap1'] = df['view']\n",
    "df['gender_m0f1'] = df['gender_m0f1'].replace({'M':0,'F':1})\n",
    "df['view_pa0_ap1'] = df['view_pa0_ap1'].replace({'PA':0,'AP':1})\n",
    "df['age_geq_50'] = df['age_geq_50'].apply(lambda x: 1 if x>=50 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29695\n",
      "1560\n",
      "28565\n",
      "1537\n",
      "20303\n",
      "945\n",
      "18751\n",
      "764\n"
     ]
    }
   ],
   "source": [
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        for k in [0,1]:\n",
    "            arr1= ((df['view_pa0_ap1']==i)&(df['age_geq_50']==j)&(df['Pneumothorax']==k))\n",
    "            print(len(df[arr1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1= ((df['view_pa0_ap1']==1)&(df['age_geq_50']==1)&(df['Pneumothorax']==1))\n",
    "len(df[arr1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a88dc7f5182e5da1801d8474c85899bd75b375bf8cebc59e548b2bda58bdd0aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

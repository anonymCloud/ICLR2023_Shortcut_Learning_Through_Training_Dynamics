{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(10000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "%autosave 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random, os, sys, argparse\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/experiments/toy_expts/')\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvgg16_kmnist_27437\\nvgg16_kmnist_patch_48316\\nvgg16_mnist_75872\\nvgg16_mnist_patch_42954\\nvgg16_cifar10_29954\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "vgg16_kmnist_27437\n",
    "vgg16_kmnist_patch_48316\n",
    "vgg16_mnist_75872\n",
    "vgg16_mnist_patch_42954\n",
    "vgg16_cifar10_29954\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'resnet18' # resnet18, vgg16, densenet121\n",
    "dataset = 'svhn' # mnist,kmnist\n",
    "add_patch_flag = False\n",
    "num_classes = 10   \n",
    "data_csv = None\n",
    "expt_name = f'resnet18_svhn_{int(random.random()*100000)}'\n",
    "save_dir = '/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/experiments/toy_expts/output/'\n",
    "\n",
    "num_epochs = 10\n",
    "lr = 0.1\n",
    "seed = 0\n",
    "num_ch = 1 # num of channels in image\n",
    "num_embs = 2000 # 1500 for mnist, 10k for cifar10\n",
    "K = 29 # K neighbours\n",
    "num_test_imgs = 100 # num of test images for plotting PD\n",
    "lp_norm = 1 # for computing KNN\n",
    "knn_pos_thresh = 0.5\n",
    "knn_neg_thresh = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a list of img paths and plots grid of images\n",
    "def plot_images(img_list, rows, cols, titles=None):\n",
    "    plt.figure(figsize=(7.5*cols,7.5*rows))\n",
    "    for i in range(rows*cols):\n",
    "        plt.subplot(rows,cols,i+1)\n",
    "        if type(img_list[0])==str:\n",
    "            img = plt.imread(img_list[i])\n",
    "        else:\n",
    "            img = img_list[i]\n",
    "        plt.imshow(img)\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to /jet/home/nmurali/asc170022p/nmurali/projects/shortcut_detection_and_mitigation/data/svhn_gray/train_32x32.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f671c9c8310143b0ab130b2492c99061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182040794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to /jet/home/nmurali/asc170022p/nmurali/projects/shortcut_detection_and_mitigation/data/svhn_gray/test_32x32.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bcaeab3da1430b823170953509b874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64275384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# datasets\n",
    "print('==> Preparing data..')\n",
    "if dataset=='mnist':\n",
    "    # transformations\n",
    "    trans = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((32,32)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "#                 torchvision.transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
    "            ])  # for mnist and fmnist we replicate channels\n",
    "\n",
    "    root_dir = '/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/data/'\n",
    "    trainset = torchvision.datasets.MNIST(root_dir, transform=trans, download=True)\n",
    "    testset = torchvision.datasets.MNIST(root_dir, train=False, transform=trans, download=True)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=500, shuffle=False, num_workers=2)\n",
    "elif dataset=='fmnist':\n",
    "    # transformations\n",
    "    trans = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((32,32)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "#                 torchvision.transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
    "            ])  # for mnist and fmnist we replicate channels\n",
    "\n",
    "    root_dir = '/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/data/'\n",
    "    trainset = torchvision.datasets.FashionMNIST(root_dir, transform=trans, download=True)\n",
    "    testset = torchvision.datasets.FashionMNIST(root_dir, train=False, transform=trans, download=True)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=500, shuffle=False, num_workers=2)\n",
    "elif dataset=='kmnist':\n",
    "    # transformations\n",
    "    trans = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((32,32)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "#                 torchvision.transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
    "            ])  # for mnist and fmnist we replicate channels\n",
    "\n",
    "    root_dir = '/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/data/'\n",
    "    trainset = torchvision.datasets.KMNIST(root_dir, transform=trans, download=True)\n",
    "    testset = torchvision.datasets.KMNIST(root_dir, train=False, transform=trans, download=True)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=500, shuffle=False, num_workers=2)\n",
    "elif dataset=='svhn':\n",
    "    # transformations\n",
    "    trans = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((32,32)),\n",
    "#                 torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ])  # for mnist and fmnist we replicate channels\n",
    "\n",
    "    root_dir = '/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/data/svhn_gray/'\n",
    "    trainset = torchvision.datasets.SVHN(root_dir, split='train', transform=trans, download=True)\n",
    "    testset = torchvision.datasets.SVHN(root_dir, split='test', transform=trans, download=True)\n",
    "    \n",
    "    trainset.targets = trainset.labels\n",
    "    testset.targets = testset.labels\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=500, shuffle=False, num_workers=2)\n",
    "elif dataset=='cifar10':\n",
    "    # transformations\n",
    "    trans = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((32,32)),\n",
    "#                 torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.4914,0.4822,0.4465],std=[0.2470,0.2435,0.2616])\n",
    "            ])  # for mnist and fmnist we replicate channels\n",
    "\n",
    "    root_dir = '/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/data/'\n",
    "    trainset = torchvision.datasets.CIFAR10(root_dir, transform=trans, download=True)\n",
    "    testset = torchvision.datasets.CIFAR10(root_dir, train=False, transform=trans, download=True)\n",
    "    \n",
    "#     # use only 2 classes\n",
    "#     arr = (np.array(trainset.targets)==0) | (np.array(trainset.targets)==1)\n",
    "#     trainset.data = trainset.data[arr]\n",
    "#     trainset.targets = np.array(trainset.targets)[arr]\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=500, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=500, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_function__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)):\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add patch shortcut\n",
    "def add_patch(img,lab):\n",
    "    mid = img.shape[0]//2\n",
    "    mid_x = mid-2\n",
    "    mid_y = mid+3    \n",
    "    if lab==0:\n",
    "        img[:4,:4] = 255\n",
    "    elif lab==1:\n",
    "        img[:4,-4:] = 255\n",
    "    elif lab==2:\n",
    "        img[-4:,:4] = 255\n",
    "    elif lab==3:\n",
    "        img[-4:,-4:] = 255\n",
    "    elif lab==4:\n",
    "        img[mid_x:mid_y,mid_x:mid_y] = 255\n",
    "    elif lab==5: \n",
    "        img[:4,12:16] = 255\n",
    "    elif lab==6:  \n",
    "        img[-4:,12:16] = 255\n",
    "    elif lab==7:\n",
    "        img[12:16,:4] = 255\n",
    "    elif lab==8:    \n",
    "        img[12:16,-4:] = 255        \n",
    "    return img\n",
    "\n",
    "if add_patch_flag:    \n",
    "    for (img,lab) in zip(trainset.data,trainset.targets):\n",
    "        img = add_patch(img,lab)        \n",
    "    for (img,lab) in zip(testset.data,testset.targets):\n",
    "        img = add_patch(img,lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCam Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # SHAP on intermediate soft-KNN outputs\n",
    "# # user hyperparams\n",
    "# expt_name = 'vgg16_kmnist_patch_48316'\n",
    "# layer_id = 3 # vgg layer to viz net.module.features[layer_id]\n",
    "#                # 0,3,7,10,14,17,20,24,27,30,34,37,40\n",
    "# train_emb_idx = 1 # info_dict['feats'][train_emb_idx]\n",
    "#               # 0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "\n",
    "# # load model\n",
    "# train_embs_pkl_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "# net = nn.DataParallel(customVGG2('VGG16', train_embs_pkl_path, layer_id, train_emb_idx, num_channels=1))\n",
    "# net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "# net.eval()\n",
    "\n",
    "# # load batch of images\n",
    "# batch = next(iter(testloader))\n",
    "# images, _ = batch\n",
    "\n",
    "# # prepare shap train and test images\n",
    "# shap_train_imgs = images[:50].to('cuda')\n",
    "# shap_test_imgs = images[490:].to('cuda')\n",
    "\n",
    "# e = shap.DeepExplainer(net, shap_train_imgs)\n",
    "# shap_values = e.shap_values(shap_test_imgs)\n",
    "\n",
    "# shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "# test_numpy = np.swapaxes(np.swapaxes(shap_test_imgs.cpu().numpy(), 1, -1), 1, 2)\n",
    "# shap.image_plot(shap_numpy, -test_numpy, width=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GradCAM on intermediate soft-KNN outputs\n",
    "# user hyperparams\n",
    "expt_name = 'vgg16_kmnist_patch_84442'\n",
    "layer_id = 0 # vgg layer to viz net.module.features[layer_id]\n",
    "               # 0,3,7,10,14,17,20,24,27,30,34,37,40\n",
    "train_emb_idx = 0 # info_dict['feats'][train_emb_idx]\n",
    "              # 0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "\n",
    "# load model\n",
    "train_embs_pkl_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "net = nn.DataParallel(customVGG2('VGG16', train_embs_pkl_path, layer_id, train_emb_idx, num_channels=1))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()\n",
    "\n",
    "# loop over test images\n",
    "for _ in range(25):\n",
    "    img_id = int(random.random()*len(trainset.data))\n",
    "    img = trainset.data[img_id]\n",
    "    \n",
    "    # pre-process the img to make it compatible for forward pass\n",
    "    to_pil_trans = transforms.ToPILImage()\n",
    "    if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "        img_tensor = to_pil_trans(img.squeeze().to('cuda'))\n",
    "    else:\n",
    "        img_tensor = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "    img_tensor = trans(img_tensor).unsqueeze(0)\n",
    "    if img_tensor.shape[1]==4:\n",
    "        img_tensor = img_tensor[:,0,:,:].unsqueeze(0)\n",
    "        \n",
    "    img_rgb = img_tensor.squeeze().unsqueeze(-1).expand(32,32,3)\n",
    "\n",
    "    # gradCAM code\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "    target_layers = [net.module.features[layer_id]]\n",
    "\n",
    "    cam = GradCAM(model=net, target_layers=target_layers, use_cuda=True)\n",
    "    grayscale_cams = cam(input_tensor=img_tensor, targets=targets, aug_smooth=False, eigen_smooth=False)\n",
    "    cam_op = show_cam_on_image(np.array(img_rgb)*0.35, (grayscale_cams[0]>0.8).astype(float)*20, use_rgb=True)\n",
    "    \n",
    "    img_list = []\n",
    "    img_list.append(img_rgb)\n",
    "    img_list.append(grayscale_cams[0])\n",
    "    img_list.append((grayscale_cams[0]>0.8).astype(float))\n",
    "    img_list.append(cam_op)\n",
    "\n",
    "    # plot results\n",
    "    plot_images(img_list,rows=1,cols=4,titles=[f'Img Id: {img_id}','Heatmap','Thresholded Heatmap','Overlay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_op.shape, img_rgb.shape, grayscale_cams[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Figs to Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 45456# 45456 , 50547\n",
    "img = trainset.data[img_id]\n",
    "\n",
    "# pre-process the img to make it compatible for forward pass\n",
    "to_pil_trans = transforms.ToPILImage()\n",
    "if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "    img_tensor = to_pil_trans(img.squeeze().to('cuda'))\n",
    "else:\n",
    "    img_tensor = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "img_tensor = trans(img_tensor).unsqueeze(0)\n",
    "if img_tensor.shape[1]==4:\n",
    "    img_tensor = img_tensor[:,0,:,:].unsqueeze(0)\n",
    "\n",
    "img_rgb = img_tensor.squeeze().unsqueeze(-1).expand(32,32,3)\n",
    "\n",
    "# gradCAM code\n",
    "targets = [ClassifierOutputTarget(0)]\n",
    "target_layers = [net.module.features[layer_id]]\n",
    "\n",
    "cam = GradCAM(model=net, target_layers=target_layers, use_cuda=True)\n",
    "grayscale_cams = cam(input_tensor=img_tensor, targets=targets, aug_smooth=False, eigen_smooth=False)\n",
    "cam_op = show_cam_on_image(np.array(img_rgb)*0.35, (grayscale_cams[0]>0.8).astype(float)*20, use_rgb=True)\n",
    "\n",
    "img_list = []\n",
    "img_list.append(img_rgb)\n",
    "img_list.append(grayscale_cams[0])\n",
    "img_list.append((grayscale_cams[0]>0.8).astype(float))\n",
    "img_list.append(cam_op)\n",
    "\n",
    "# plot results\n",
    "plot_images(img_list,rows=1,cols=4,titles=['Original Img','Heatmap','Thresholded Heatmap','Overlay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off') \n",
    "plt.imshow(cam_op)\n",
    "plt.imsave('/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/experiments/paper_quality_plots/results/kmnist_patch_2b.svg',cam_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off') \n",
    "plt.imshow(img_rgb)\n",
    "plt.imsave('/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/experiments/paper_quality_plots/results/kmnist_patch_2a.svg',img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 573/573 [00:33<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572 573 Loss: 1.709 | Acc: 41.378% (30312/73257)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:03<00:00, 16.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 53 Loss: 0.895 | Acc: 72.968% (18995/26032)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 573/573 [00:33<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572 573 Loss: 0.431 | Acc: 86.713% (63523/73257)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:03<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 53 Loss: 0.342 | Acc: 89.513% (23302/26032)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 573/573 [00:34<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572 573 Loss: 0.277 | Acc: 91.650% (67140/73257)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:03<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 53 Loss: 0.296 | Acc: 91.126% (23722/26032)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 40/573 [00:02<00:35, 15.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24193/4030017974.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24193/4030017974.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "if model=='resnet18':\n",
    "    # net = VGG('VGG19')\n",
    "    net = ResNet18(num_channels=num_ch)\n",
    "    # net = PreActResNet18()\n",
    "    # net = GoogLeNet()\n",
    "    # net = DenseNet121()\n",
    "    # net = ResNeXt29_2x64d()\n",
    "    # net = MobileNet()\n",
    "    # net = MobileNetV2()\n",
    "    # net = DPN92()\n",
    "    # net = ShuffleNetG2()\n",
    "    # net = SENet18()\n",
    "    # net = ShuffleNetV2(1)\n",
    "    # net = EfficientNetB0()\n",
    "    # net = RegNetX_200MF()\n",
    "    # net = SimpleDLA()\n",
    "elif model=='vgg16':\n",
    "    net = VGG('VGG16',num_channels=num_ch)\n",
    "elif model=='densenet121':\n",
    "    net = DenseNet121()\n",
    "net = net.to(device)\n",
    "    \n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                 % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(testloader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "#         if not os.path.isdir(f'{args['expt_name']}_checkpoint'):\n",
    "#             os.mkdir('checkpoint')\n",
    "        torch.save(state, os.path.join(save_dir,f'{expt_name}.pt'))\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Train (subset) embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load checkpoint\n",
    "# expt_name = 'vgg16_cifar10_29954'\n",
    "if model=='resnet18':\n",
    "    net = nn.DataParallel(ResNet18(num_channels=num_ch))\n",
    "elif model=='vgg16':\n",
    "    net = nn.DataParallel(VGG('VGG16',num_channels=num_ch))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding hook function for resnet18\n",
    "# def add_resnet18_hooks(net, hook):\n",
    "#     net.module.bn1.register_forward_hook(hook)\n",
    "    \n",
    "#     net.module.layer1[0].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer1[0].shortcut.register_forward_hook(hook)\n",
    "    \n",
    "#     net.module.layer1[1].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer1[1].shortcut.register_forward_hook(hook)\n",
    "\n",
    "#     net.module.layer2[0].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer2[0].shortcut.register_forward_hook(hook)\n",
    "    \n",
    "#     net.module.layer2[1].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer2[1].shortcut.register_forward_hook(hook)\n",
    "    \n",
    "#     net.module.layer3[0].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer3[0].shortcut.register_forward_hook(hook)\n",
    "    \n",
    "#     net.module.layer3[1].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer3[1].shortcut.register_forward_hook(hook)\n",
    "    \n",
    "#     net.module.layer4[0].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer4[0].shortcut.register_forward_hook(hook)\n",
    "    \n",
    "#     net.module.layer4[1].bn1.register_forward_hook(hook)\n",
    "#     net.module.layer4[1].shortcut.register_forward_hook(hook)\n",
    "        \n",
    "#     return net\n",
    "\n",
    "def add_resnet18_hooks(net, hook):\n",
    "    net.module.bn1.register_forward_hook(hook)\n",
    "    \n",
    "    net.module.layer1[0].conv1.register_forward_hook(hook)\n",
    "    net.module.layer1[0].conv2.register_forward_hook(hook)\n",
    "    \n",
    "    net.module.layer1[1].conv1.register_forward_hook(hook)\n",
    "    net.module.layer1[1].conv2.register_forward_hook(hook)\n",
    "\n",
    "    net.module.layer2[0].conv1.register_forward_hook(hook)\n",
    "    net.module.layer2[0].conv2.register_forward_hook(hook)\n",
    "    \n",
    "    net.module.layer2[1].conv1.register_forward_hook(hook)\n",
    "    net.module.layer2[1].conv2.register_forward_hook(hook)\n",
    "    \n",
    "    net.module.layer3[0].conv1.register_forward_hook(hook)\n",
    "    net.module.layer3[0].conv2.register_forward_hook(hook)\n",
    "    \n",
    "    net.module.layer3[1].conv1.register_forward_hook(hook)\n",
    "    net.module.layer3[1].conv2.register_forward_hook(hook)\n",
    "    \n",
    "    net.module.layer4[0].conv1.register_forward_hook(hook)\n",
    "    net.module.layer4[0].conv2.register_forward_hook(hook)\n",
    "    \n",
    "    net.module.layer4[1].conv1.register_forward_hook(hook)\n",
    "    net.module.layer4[1].conv2.register_forward_hook(hook)\n",
    "        \n",
    "    return net\n",
    "\n",
    "def add_vgg16_hooks(net, hook):\n",
    "    net.module.features[0].register_forward_hook(hook)\n",
    "    net.module.features[3].register_forward_hook(hook)\n",
    "    net.module.features[7].register_forward_hook(hook)\n",
    "    net.module.features[10].register_forward_hook(hook)\n",
    "    net.module.features[14].register_forward_hook(hook)\n",
    "    net.module.features[17].register_forward_hook(hook)\n",
    "    net.module.features[20].register_forward_hook(hook)\n",
    "    net.module.features[24].register_forward_hook(hook)\n",
    "    net.module.features[27].register_forward_hook(hook)\n",
    "    net.module.features[30].register_forward_hook(hook)\n",
    "    net.module.features[34].register_forward_hook(hook)\n",
    "    net.module.features[37].register_forward_hook(hook)\n",
    "    net.module.features[40].register_forward_hook(hook)        \n",
    "    return net\n",
    "\n",
    "def add_densenet121_hooks(net, hook):\n",
    "    \n",
    "    for idx,layer in enumerate(net.module.dense1):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(net.module.dense2):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(net.module.dense3):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    for idx,layer in enumerate(net.module.dense4):\n",
    "        if idx%2==0:\n",
    "            layer.register_forward_hook(hook)\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "def hook_feat_map(mod, inp, out):\n",
    "    out = torch.nn.functional.interpolate(out,(8,8))\n",
    "#     feature_maps.append(torch.mean(out,dim=[2,3]))\n",
    "    feature_maps.append(torch.reshape(out, (out.shape[0],-1)))\n",
    "\n",
    "if model=='resnet18':\n",
    "    net = add_resnet18_hooks(net, hook_feat_map)\n",
    "elif model=='vgg16':\n",
    "    net = add_vgg16_hooks(net, hook_feat_map)\n",
    "elif model=='densenet121':\n",
    "    net = add_densenet121_hooks(net, hook_feat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_cpu(arr):\n",
    "    for idx,x in enumerate(arr):\n",
    "        arr[idx] = x.to('cpu')\n",
    "    return arr\n",
    "\n",
    "def print_memory_profile(s):\n",
    "    # print GPU memory\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    print(s)\n",
    "    print(t/1024**3,r/1024**3,a/1024**3)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # something wrong here with my equal sampling I think\n",
    "# if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "#     imgs = torch.empty((0,trainset.data[0].shape[0],trainset.data[0].shape[1]))\n",
    "# else:\n",
    "#     imgs = torch.empty((0,trainset.data[0].shape[0],trainset.data[0].shape[1],trainset.data[0].shape[2]))\n",
    "# targs = torch.empty(0)\n",
    "\n",
    "# for i in tqdm(range(num_classes)): \n",
    "#     cls_inds = (torch.tensor(trainset.targets)==i).nonzero(as_tuple=True)[0]\n",
    "\n",
    "#     # randomly permute cls_inds, and subsample\n",
    "#     # in total we want 3k samples of train embeddings\n",
    "#     perm = torch.randperm(cls_inds.size(0))\n",
    "#     inds = perm[:num_embs//num_classes]\n",
    "#     cls_inds = cls_inds[inds]\n",
    "#     samples = torch.tensor(trainset.data[cls_inds])\n",
    "#     imgs = torch.cat((imgs,samples)) # this will have num_embs samples finally    \n",
    "#     targs = torch.cat((targs,torch.ones_like(cls_inds)*i))\n",
    "    \n",
    "# if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "#     # resize again to 32x32\n",
    "#     imgs_resized = torch.empty((0,32,32))\n",
    "#     T = transforms.ToPILImage()\n",
    "#     for img in imgs:\n",
    "#         imgs_resized = torch.cat((imgs_resized,trans(T(img))))\n",
    "#     train_subset = torch.utils.data.TensorDataset(imgs_resized,targs)\n",
    "# else:    \n",
    "#     train_subset = torch.utils.data.TensorDataset(imgs,targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = torch.tensor(trainset.targets)\n",
    "perm = torch.randperm(labs.size(0))\n",
    "inds = perm[:num_embs]\n",
    "labs = labs[inds]\n",
    "samples = torch.tensor(trainset.data)[inds]\n",
    "\n",
    "if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "    # resize again to 32x32\n",
    "    samples_resized = torch.empty((0,32,32))\n",
    "    T = transforms.ToPILImage()\n",
    "    for img in samples:\n",
    "        samples_resized = torch.cat((samples_resized,trans(T(img))))\n",
    "    train_subset = torch.utils.data.TensorDataset(samples_resized,labs)\n",
    "else:\n",
    "    train_subset = torch.utils.data.TensorDataset(samples,labs)\n",
    "trainloader2 = torch.utils.data.DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257, 3, 32, 32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial\n",
      "15.74737548828125 1.8046875 0.8583168983459473\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 3, 3], expected input[2000, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24193/44320055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfeature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0minfo_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch_idx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'num_batches'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feats'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature_maps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/projects/shortcut_detection_and_mitigation/experiments/toy_expts/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 3, 3], expected input[2000, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "# code for saving pkl file of layer embeddings\n",
    "save_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "trainloader2 = torch.utils.data.DataLoader(train_subset, batch_size=30000, shuffle=True, num_workers=2)\n",
    "\n",
    "handle = open(save_path, \"wb\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for b_idx,batch in enumerate(tqdm(trainloader2)):        \n",
    "        # print GPU memory\n",
    "        print_memory_profile('Initial')\n",
    "        \n",
    "        if dataset=='mnist'  or dataset=='kmnist' or dataset=='fmnist':\n",
    "            imgs = batch[0].unsqueeze(1).to('cuda')\n",
    "        elif dataset=='svhn':\n",
    "            imgs = batch[0].to('cuda')\n",
    "        else:\n",
    "            imgs = batch[0].permute(0,3,1,2).to('cuda')\n",
    "        labels = batch[1]\n",
    "        \n",
    "        feature_maps = []\n",
    "        out = net(imgs.float())\n",
    "        \n",
    "        info_dict = {'batch_idx':b_idx,'num_batches':len(trainloader2),'feats':feature_maps,'labels':labels}\n",
    "        pickle.dump(info_dict, handle)  \n",
    "        \n",
    "        # print GPU memory\n",
    "        print_memory_profile('After processing Batch')\n",
    "        \n",
    "        # free up GPU memory\n",
    "        del feature_maps, info_dict\n",
    "        torch.cuda.empty_cache()     \n",
    "        \n",
    "        # print GPU memory\n",
    "        print_memory_profile('After freeing GPU memory')\n",
    "        \n",
    "handle.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_pd.py\n",
    "\n",
    "def compute_pred_depth(arr):\n",
    "    last = arr[-1]\n",
    "\n",
    "    p_depth = 1\n",
    "    for i in range(len(arr)-1):\n",
    "        ele = arr[-1-(i+1)]\n",
    "        if ele!=last:\n",
    "            p_depth = (len(arr)-(i+1)) + 1\n",
    "            break\n",
    "    \n",
    "    return p_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = torch.tensor(testset.targets)\n",
    "perm = torch.randperm(labs.size(0))\n",
    "inds = perm[:num_test_imgs]\n",
    "labs = labs[inds]\n",
    "samples = torch.tensor(testset.data)[inds]\n",
    "\n",
    "if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "    # resize again to 32x32\n",
    "    samples_resized = torch.empty((0,32,32))\n",
    "    T = transforms.ToPILImage()\n",
    "    for img in samples:\n",
    "        samples_resized = torch.cat((samples_resized,trans(T(img))))\n",
    "    test_subset = torch.utils.data.TensorDataset(samples_resized,labs)\n",
    "else:\n",
    "    test_subset = torch.utils.data.TensorDataset(samples,labs)\n",
    "testloader2 = torch.utils.data.DataLoader(test_subset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial\n",
      "15.74737548828125 0.5546875 0.19965219497680664\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===================== Storing Batch Statistics =====================\n",
    "\n",
    "batch_info = {}\n",
    "train_embs_pkl_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "ckpt_path = os.path.join(save_dir,f'{expt_name}.pt')\n",
    "batch_info['readme'] = f'---- K={K} ---- ckpt_path={ckpt_path} ---- pkl_path={train_embs_pkl_path} ----'\n",
    "batch_info['imgs'] = [] # test images\n",
    "batch_info['preds'] = [] # corresponding model predictions\n",
    "batch_info['pred_probs'] = [] # corresponding model predictions\n",
    "batch_info['labels'] = [] # labels of the test images\n",
    "batch_info['pd'] = [] # corresponding prediction depths\n",
    "batch_info['layers_knn_prob'] = [] # for each test image we have a list of knn means for every layer\n",
    "batch_info['layers_knn_mode'] = [] # for each test image we have a list of knn mode for every layer\n",
    "\n",
    "print_memory_profile('Initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/73257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT = tensor([[-2.3169,  4.4160,  1.4943,  0.8134,  2.0611, -0.3125, -2.5466, -0.9567,\n",
      "         -1.6974, -1.0850]], device='cuda:0')\n",
      "Model output: 4.41601037979126\n",
      "Model forward pass\n",
      "15.74737548828125 0.55859375 0.20050859451293945\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle load\n",
      "15.74737548828125 2.15234375 2.0664753913879395\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "17it [00:00, 54.45it/s][A\n",
      "  0%|          | 1/73257 [00:01<38:53:03,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 3.04296875 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 0\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 1\n",
      "pred: 1\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[ 3.1817, -1.0961,  0.7027, -0.9061, -2.1870, -2.0103, -1.9695, -1.9875,\n",
      "         -1.6507,  7.7351]], device='cuda:0')\n",
      "Model output: 7.7350921630859375\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 590.37it/s]\n",
      "  0%|          | 2/73257 [00:02<27:11:59,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 1\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 9\n",
      "pred: 9\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-2.6573, -0.2335,  8.8751,  0.5429,  0.8332, -1.7339, -2.2681,  0.4019,\n",
      "         -2.1427, -1.7128]], device='cuda:0')\n",
      "Model output: 8.875146865844727\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 584.43it/s]\n",
      "  0%|          | 3/73257 [00:03<23:05:06,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 2\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 2\n",
      "pred: 2\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-2.1956, -0.8705, -2.9602,  5.9024, -2.1392,  1.6013,  1.1003, -2.0133,\n",
      "          3.3484, -1.8171]], device='cuda:0')\n",
      "Model output: 5.902356147766113\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 583.50it/s]\n",
      "  0%|          | 4/73257 [00:04<21:06:47,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 3\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 3\n",
      "pred: 3\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-1.7177,  1.2502,  3.6303,  0.9694,  0.6095, -0.5386, -1.7241,  0.8527,\n",
      "         -1.6024, -1.7019]], device='cuda:0')\n",
      "Model output: 3.63034725189209\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.28it/s]\n",
      "  0%|          | 5/73257 [00:05<20:00:33,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 4\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 2\n",
      "pred: 2\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-1.9235,  0.8436, -0.0220,  0.2067,  0.2407,  2.3382,  0.3926,  0.3928,\n",
      "         -1.2446, -1.2324]], device='cuda:0')\n",
      "Model output: 2.3381552696228027\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.67it/s]\n",
      "  0%|          | 6/73257 [00:06<19:21:22,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 5\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 5\n",
      "pred: 5\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[ 1.4319, -0.2270,  0.4656,  0.3124, -1.3517,  0.3487, -1.1280, -1.5143,\n",
      "         -1.9230,  3.4923]], device='cuda:0')\n",
      "Model output: 3.4922502040863037\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.79it/s]\n",
      "  0%|          | 7/73257 [00:07<18:56:26,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 6\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 9\n",
      "pred: 9\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-0.4808,  0.1448, -2.9323,  4.2984, -2.1545,  3.6682, -1.2430, -2.5609,\n",
      "          0.6250,  0.6039]], device='cuda:0')\n",
      "Model output: 4.298409938812256\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 583.75it/s]\n",
      "  0%|          | 8/73257 [00:08<18:40:05,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 7\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 3\n",
      "pred: 3\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-3.7148, -0.2522, -1.6718,  8.0153, -1.7315,  1.3782, -1.5848, -0.2838,\n",
      "          1.4772, -1.6283]], device='cuda:0')\n",
      "Model output: 8.015281677246094\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 582.94it/s]\n",
      "  0%|          | 9/73257 [00:09<18:29:16,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 8\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 3\n",
      "pred: 3\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[ 2.0165,  5.8242, -2.6424,  0.6691, -2.0487, -2.1193, -1.6137,  0.8693,\n",
      "          0.1547, -1.1614]], device='cuda:0')\n",
      "Model output: 5.824234962463379\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 588.36it/s]\n",
      "  0%|          | 10/73257 [00:09<18:22:55,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 9\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 1\n",
      "pred: 1\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-2.7866,  1.2304, -1.0345,  5.6720, -0.6720,  2.2965, -3.1932, -2.2353,\n",
      "          0.0584,  0.6913]], device='cuda:0')\n",
      "Model output: 5.671985626220703\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.75it/s]\n",
      "  0%|          | 11/73257 [00:10<18:17:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 10\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 3\n",
      "pred: 3\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[ 0.6032,  1.4344, -2.2476,  3.2158, -1.1702,  0.6610, -1.3311, -1.0093,\n",
      "          0.3189, -0.5533]], device='cuda:0')\n",
      "Model output: 3.2157974243164062\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 584.56it/s]\n",
      "  0%|          | 12/73257 [00:11<18:18:55,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 11\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 3\n",
      "pred: 3\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-2.6284,  0.3044,  7.2094,  0.4738, -0.3660, -1.0324, -3.2558, -1.0712,\n",
      "         -1.1299,  1.3379]], device='cuda:0')\n",
      "Model output: 7.2093915939331055\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 585.76it/s]\n",
      "  0%|          | 13/73257 [00:12<18:17:11,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 12\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 2\n",
      "pred: 2\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-1.0274, -1.3677,  0.7373,  0.4236, -2.0689, -3.3107,  0.8893, -3.1246,\n",
      "          8.5646,  0.1917]], device='cuda:0')\n",
      "Model output: 8.564595222473145\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.50it/s]\n",
      "  0%|          | 14/73257 [00:13<18:15:04,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 13\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 8\n",
      "pred: 8\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-1.6335,  3.0228, -0.9427,  2.0548, -1.1430, -1.0570, -1.5242,  3.7882,\n",
      "         -0.9935, -1.5994]], device='cuda:0')\n",
      "Model output: 3.788245916366577\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 584.48it/s]\n",
      "  0%|          | 15/73257 [00:14<18:13:55,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 14\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 7\n",
      "pred: 7\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[ 0.3678,  2.2874,  0.0295, -1.0879,  4.2373, -1.7931, -1.0680, -1.2591,\n",
      "         -1.0877, -0.7436]], device='cuda:0')\n",
      "Model output: 4.23727560043335\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 583.45it/s]\n",
      "  0%|          | 16/73257 [00:15<18:13:06,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 15\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 4\n",
      "pred: 4\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-0.3210,  0.4104,  0.3135, -0.2732,  2.2549, -0.4521, -0.6606, -2.1330,\n",
      "          0.2958,  0.5196]], device='cuda:0')\n",
      "Model output: 2.25490665435791\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 582.90it/s]\n",
      "  0%|          | 17/73257 [00:16<18:12:11,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 16\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 4\n",
      "pred: 4\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-0.2843,  6.8236, -2.2970, -0.2731,  0.7689, -0.8554, -1.0345, -0.3251,\n",
      "         -0.7099, -1.8781]], device='cuda:0')\n",
      "Model output: 6.823625564575195\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 582.74it/s]\n",
      "  0%|          | 18/73257 [00:17<18:12:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 17\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 1\n",
      "pred: 1\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-1.7647,  0.8393,  8.2434, -0.5555, -0.7539, -1.9993, -3.1617, -0.3592,\n",
      "         -2.2501,  1.5733]], device='cuda:0')\n",
      "Model output: 8.243439674377441\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 583.61it/s]\n",
      "  0%|          | 19/73257 [00:18<18:11:37,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 18\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 2\n",
      "pred: 2\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-0.9566, -1.2263, -0.2911, -1.0543, -1.5777, -1.8390,  3.1224, -3.0737,\n",
      "          7.0902, -0.3077]], device='cuda:0')\n",
      "Model output: 7.090194225311279\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.03it/s]\n",
      "  0%|          | 20/73257 [00:18<18:11:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 19\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 8\n",
      "pred: 8\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-0.4462,  7.8902, -2.3710, -0.5747,  0.0968, -1.8827,  0.6108, -0.1579,\n",
      "          0.0836, -3.3362]], device='cuda:0')\n",
      "Model output: 7.890164375305176\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 581.68it/s]\n",
      "  0%|          | 21/73257 [00:19<18:10:47,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 20\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 1\n",
      "pred: 1\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[ 0.2651, -1.6845, -3.0385, -1.2767,  1.7769, -0.4829,  9.5122, -2.8378,\n",
      "          1.6704, -4.0672]], device='cuda:0')\n",
      "Model output: 9.512192726135254\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 591.33it/s]\n",
      "  0%|          | 22/73257 [00:20<18:10:24,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 21\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 6\n",
      "pred: 6\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-3.0577,  0.3351,  4.8017,  1.9435,  0.4935, -1.4989, -2.8242,  0.3052,\n",
      "         -0.3884, -0.2087]], device='cuda:0')\n",
      "Model output: 4.801652431488037\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.23it/s]\n",
      "  0%|          | 23/73257 [00:21<18:12:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 22\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 2\n",
      "pred: 2\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-1.7090,  2.4042, -2.8460,  2.0873,  1.3469,  2.0399, -1.1777, -2.2761,\n",
      "          0.3035, -0.2231]], device='cuda:0')\n",
      "Model output: 2.404247760772705\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 594.25it/s]\n",
      "  0%|          | 24/73257 [00:22<18:13:07,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 23\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 3\n",
      "pred: 1\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-1.4196,  0.0862, -2.4740, -0.2790,  1.4694, -0.2874,  8.2685, -1.9384,\n",
      "          1.1861, -4.7407]], device='cuda:0')\n",
      "Model output: 8.268526077270508\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 590.98it/s]\n",
      "  0%|          | 25/73257 [00:23<18:12:27,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 24\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 6\n",
      "pred: 6\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-4.1858,  0.0725, -3.2451, 10.5903, -2.1414,  2.4309, -3.0112,  0.1185,\n",
      "          0.8443, -1.5718]], device='cuda:0')\n",
      "Model output: 10.590331077575684\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 590.33it/s]\n",
      "  0%|          | 26/73257 [00:24<18:12:38,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 25\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 3\n",
      "pred: 3\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-2.4020,  1.7172, -1.3701, -1.7950, 10.3772, -1.3651,  0.1873, -1.0556,\n",
      "         -2.8583, -1.5762]], device='cuda:0')\n",
      "Model output: 10.37724781036377\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 586.32it/s]\n",
      "  0%|          | 27/73257 [00:25<18:12:28,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 26\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 4\n",
      "pred: 4\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-3.0353,  0.5456,  8.7098,  0.5617,  1.4419, -1.8849, -2.5908,  0.2058,\n",
      "         -1.8346, -2.2226]], device='cuda:0')\n",
      "Model output: 8.709750175476074\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n",
      "Pickle load\n",
      "15.74737548828125 2.396484375 2.310746669769287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 594.20it/s]\n",
      "  0%|          | 28/73257 [00:26<18:12:10,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle batch processed\n",
      "15.74737548828125 2.640625 2.066483974456787\n",
      "\n",
      "\n",
      "After GPU memory freed\n",
      "15.74737548828125 0.80078125 0.4446578025817871\n",
      "\n",
      "\n",
      "Test Image: 27\n",
      "knn_preds_mode: [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0]\n",
      "knn_preds_prob: [0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.17241379618644714, 0.2068965584039688, 0.17241379618644714, 0.2068965584039688, 0.2068965584039688, 0.17241379618644714]\n",
      "label: 2\n",
      "pred: 2\n",
      "\n",
      "\n",
      "Invalid datapoint: last_layer_mode != model_output\n",
      "OUT = tensor([[-3.5703, -0.2413, -1.2973,  1.9218, -1.5113,  7.6797,  0.8878, -2.7515,\n",
      "         -1.3986,  0.0954]], device='cuda:0')\n",
      "Model output: 7.679699897766113\n",
      "Model forward pass\n",
      "15.74737548828125 0.802734375 0.4447798728942871\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/73257 [00:26<19:32:53,  1.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24193/3853102389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint_memory_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model forward pass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embs_pkl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0minfo_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mprint_memory_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pickle load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc170022p/nmurali/anaconda3/envs/pl/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop over test images\n",
    "invalid_counter = 0 # for invalid predictions (last layer mode != model output)\n",
    "for test_id, (img,lab) in enumerate(tqdm(trainset)):\n",
    "    img = img.permute([1,2,0])\n",
    "    batch_info['imgs'].append(img)\n",
    "    with torch.no_grad():\n",
    "        to_pil_trans = transforms.ToPILImage()\n",
    "        if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "            img = to_pil_trans(img.to('cuda'))\n",
    "        else:\n",
    "            img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "        img = trans(img).unsqueeze(0)\n",
    "        lab = int(lab)\n",
    "        if img.shape[1]==4:\n",
    "            img = img[:,0,:,:].unsqueeze(0)\n",
    "        feature_maps = []\n",
    "        out = net(img)\n",
    "        print(f'OUT = {out}')\n",
    "        print(f'Model output: {out.max()}')\n",
    "        batch_info['preds'].append(int(out.argmax()))\n",
    "        batch_info['pred_probs'].append(float(torch.nn.functional.softmax(out).max()))\n",
    "        batch_info['labels'].append(lab)\n",
    "\n",
    "        print_memory_profile('Model forward pass')\n",
    "        with open(train_embs_pkl_path, 'rb') as handle:            \n",
    "            info_dict = pickle.load(handle)\n",
    "            print_memory_profile('Pickle load')\n",
    "\n",
    "            # loop over layers in densenet, and compute KNN for this test image\n",
    "            knn_preds_mode = []  # layer-wise final KNN classification preds   \n",
    "            knn_preds_prob = []\n",
    "            for layer_id,feat in tqdm(enumerate(feature_maps)):\n",
    "                X_i = feat.unsqueeze(1)  # (10000, 1, 784) test set\n",
    "                X_j = info_dict['feats'][layer_id].unsqueeze(0)  # (1, 60000, 784) train set\n",
    "                if lp_norm==2:\n",
    "                    D_ij = ((X_i - X_j) ** 2).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "                elif lp_norm==1:\n",
    "                    D_ij = (abs(X_i - X_j)).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "                else:\n",
    "                    raise('Invalid lp_norm in arguments!')\n",
    "\n",
    "                ind_knn = torch.topk(-D_ij,K,dim=1)  # Samples <-> Dataset, (N_test, K)\n",
    "                lab_knn = info_dict['labels'][ind_knn[1]]  # (N_test, K) array of integers in [0,9]\n",
    "#                 print(f'!!!!!!test_img:{test_id}, nbrs in layer {layer_id}: {ind_knn[1]}')\n",
    "                mode = int(lab_knn.squeeze().mode()[0])\n",
    "                knn_preds_mode.append(mode)\n",
    "                knn_preds_prob.append(float((lab_knn==mode).float().mean()))\n",
    "\n",
    "            print_memory_profile('Pickle batch processed')\n",
    "\n",
    "            # free GPU memory\n",
    "            del info_dict\n",
    "            torch.cuda.empty_cache()\n",
    "            print_memory_profile('After GPU memory freed') \n",
    "\n",
    "            print('Test Image: %d' %(test_id))\n",
    "            print(f'knn_preds_mode: {knn_preds_mode}')\n",
    "            print(f'knn_preds_prob: {knn_preds_prob}')\n",
    "            print(f'label: {lab}')\n",
    "            print(f'pred: {int(out.argmax())}')\n",
    "            print('\\n')\n",
    "            batch_info['layers_knn_prob'].append(knn_preds_prob)\n",
    "            batch_info['layers_knn_mode'].append(knn_preds_mode)\n",
    "            if int(out.argmax())==knn_preds_mode[-1]: # PD accurate\n",
    "                if knn_pos_thresh==0.5 and knn_neg_thresh==0.5:\n",
    "                    batch_info['pd'].append(compute_pred_depth(knn_preds_mode))\n",
    "                else:\n",
    "                    raise('Code not ready yet! Compute pred arr function also has to be updated!')\n",
    "            else: # PD inaccurate, KNN pred doesn't match model pred\n",
    "                print('Invalid datapoint: last_layer_mode != model_output')\n",
    "                invalid_counter += 1\n",
    "                batch_info['pd'].append(-99)\n",
    "print(f'Invalid Counts Ratio: {invalid_counter}/{num_test_imgs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Save results =====================\n",
    "\n",
    "with open(os.path.join(save_dir,expt_name+'_testPDinfo.pkl'), 'wb') as handle:\n",
    "    pickle.dump(batch_info, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 28 but corresponding boolean dimension is 29",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24193/598966596.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# plt.ylim((0,80))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrect_preds_arr\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# plt.hist(batch_info['pd'][~correct_preds_arr ],bins=100,color='r',alpha=0.55)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpt_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_PDplot.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 28 but corresponding boolean dimension is 29"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot PDs histogram\n",
    "with open(os.path.join(save_dir,expt_name+'_testPDinfo.pkl'), 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "\n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "correct_preds_arr = (batch_info['preds']==batch_info['labels'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title(expt_name)\n",
    "plt.ylabel('# of Images')\n",
    "plt.xlabel('Layer')\n",
    "if model=='resnet18':\n",
    "    plt.xlim((0,18))\n",
    "elif model=='vgg16':\n",
    "    plt.xlim((0,16))\n",
    "# plt.ylim((0,80))\n",
    "plt.hist(batch_info['pd'][correct_preds_arr ],bins=100,color='g',alpha=0.55)\n",
    "# plt.hist(batch_info['pd'][~correct_preds_arr ],bins=100,color='r',alpha=0.55)\n",
    "plt.savefig(os.path.join(save_dir,expt_name+'_PDplot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9997909665107727,\n",
       " 0.9929024577140808,\n",
       " 0.9909534454345703,\n",
       " 0.9991387128829956,\n",
       " 0.9986586570739746,\n",
       " 0.9876435995101929,\n",
       " 0.9996235370635986,\n",
       " 0.9931790828704834,\n",
       " 0.9993667006492615,\n",
       " 0.9989110231399536,\n",
       " 0.9999932050704956,\n",
       " 0.9864609241485596,\n",
       " 0.9990491271018982,\n",
       " 0.9977049231529236,\n",
       " 0.9992374181747437,\n",
       " 0.9998973608016968,\n",
       " 0.9969248175621033,\n",
       " 0.998752236366272,\n",
       " 0.9489956498146057,\n",
       " 0.9896492958068848,\n",
       " 0.999805748462677,\n",
       " 0.9978311657905579,\n",
       " 0.9990193843841553,\n",
       " 0.9819990396499634,\n",
       " 0.4774087965488434,\n",
       " 0.999976396560669,\n",
       " 0.9999833106994629,\n",
       " 0.9998514652252197,\n",
       " 0.9989135265350342,\n",
       " 0.9999936819076538,\n",
       " 0.9999985694885254,\n",
       " 0.9990562796592712,\n",
       " 0.9995755553245544,\n",
       " 0.9868789315223694,\n",
       " 0.9995360374450684,\n",
       " 0.9971376657485962,\n",
       " 0.9733971357345581,\n",
       " 0.9999446868896484,\n",
       " 0.9997314810752869,\n",
       " 0.9999206066131592,\n",
       " 0.9996284246444702,\n",
       " 0.998062789440155,\n",
       " 0.9959035515785217,\n",
       " 0.9997630715370178,\n",
       " 0.9950915575027466,\n",
       " 0.9940768480300903,\n",
       " 0.9997761845588684,\n",
       " 0.9999936819076538,\n",
       " 0.6805121302604675,\n",
       " 0.9940633177757263,\n",
       " 0.9999502897262573,\n",
       " 0.999110758304596,\n",
       " 0.9984696507453918,\n",
       " 0.9969874024391174,\n",
       " 0.9986653327941895,\n",
       " 0.998449444770813,\n",
       " 0.9998993873596191,\n",
       " 0.9930816292762756,\n",
       " 0.998838484287262,\n",
       " 0.9991301894187927,\n",
       " 0.9973957538604736,\n",
       " 0.9997130036354065,\n",
       " 0.9983536005020142,\n",
       " 0.9994447827339172,\n",
       " 0.9966631531715393,\n",
       " 0.9285904169082642,\n",
       " 0.9480115175247192,\n",
       " 0.9997863173484802,\n",
       " 0.9999867677688599,\n",
       " 0.9968476891517639,\n",
       " 0.999873161315918,\n",
       " 0.9767369031906128,\n",
       " 0.9995864033699036,\n",
       " 0.958698034286499,\n",
       " 0.9997389912605286,\n",
       " 0.9974467754364014,\n",
       " 0.9770933389663696,\n",
       " 0.9996421337127686,\n",
       " 0.9998685121536255,\n",
       " 0.9998462200164795,\n",
       " 0.9998257756233215,\n",
       " 0.9999678134918213,\n",
       " 0.9995548129081726,\n",
       " 0.999893069267273,\n",
       " 0.9506149888038635,\n",
       " 0.9995993971824646,\n",
       " 0.9999672174453735,\n",
       " 0.9999712705612183,\n",
       " 0.9982345104217529,\n",
       " 0.9997627139091492,\n",
       " 0.9999438524246216,\n",
       " 0.9990332126617432,\n",
       " 0.9826750159263611,\n",
       " 0.9999196529388428,\n",
       " 0.9991567134857178,\n",
       " 0.9960344433784485,\n",
       " 0.9999089241027832,\n",
       " 0.9954017400741577,\n",
       " 0.47832927107810974,\n",
       " 0.9996509552001953]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_info['pred_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz some Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = transforms.ToPILImage()\n",
    "T2 = transforms.Resize((256,256))\n",
    "# img = train_subset[100][0]\n",
    "img = testset.data[100]\n",
    "T2(T1((img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM on Intermediate Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using grad_cam_forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load checkpoint\n",
    "expt_name = 'vgg16_mnist_patch_34272'\n",
    "net = nn.DataParallel(VGG('VGG16',num_channels=1))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()\n",
    "layer_id1 = 3 # vgg layer to viz net.module.features[layer_id1]\n",
    "               # 0,3,7,10,14,17,20,24,27,30,34,37,40\n",
    "layer_id2 = 1 # info_dict['feats'][layer_id2]\n",
    "              # 0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "img_id = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hook to layer you want to viz    \n",
    "feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "def hook_feat_map(mod, inp, out):\n",
    "    feature_maps.append(torch.reshape(out, (out.shape[0],-1)))\n",
    "    \n",
    "net.module.features[layer_id1].register_forward_hook(hook_feat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the nearest K neighbours\n",
    "K = 29\n",
    "lp_norm = 1\n",
    "train_embs_pkl_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "\n",
    "img = testset.data[img_id]\n",
    "lab = testset.targets[img_id]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # make img compatible for forward pass\n",
    "    to_pil_trans = transforms.ToPILImage()\n",
    "    if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "        img = to_pil_trans(img.to('cuda'))\n",
    "    else:\n",
    "        img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "    img = trans(img).unsqueeze(0)\n",
    "    if img.shape[1]==4:\n",
    "        img = img[:,0,:,:].unsqueeze(0)\n",
    "        \n",
    "    feature_maps = []\n",
    "    out = torch.sigmoid(net(img))\n",
    "    print(f'Model output: {out}')\n",
    "    \n",
    "    with open(train_embs_pkl_path, 'rb') as handle:            \n",
    "        info_dict = pickle.load(handle)\n",
    "\n",
    "        X_i = feature_maps[0].unsqueeze(1)  # (10000, 1, 784) test set\n",
    "        X_j = info_dict['feats'][layer_id2].unsqueeze(0)  # (1, 60000, 784) train set\n",
    "        if lp_norm==2:\n",
    "            D_ij = ((X_i - X_j) ** 2).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "        elif lp_norm==1:\n",
    "            D_ij = (abs(X_i - X_j)).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "        else:\n",
    "            raise('Invalid lp_norm in arguments!')\n",
    "\n",
    "        ind_knn = torch.topk(-D_ij,K,dim=1)  # Samples <-> Dataset, (N_test, K)\n",
    "        lab_knn = info_dict['labels'][ind_knn[1]]  # (N_test, K) array of integers in [0,9]\n",
    "\n",
    "\n",
    "    # free GPU memory\n",
    "    del info_dict\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_inds = np.array(ind_knn[1][0].detach().cpu())\n",
    "nbr_feats = X_j[0,nbr_inds,:].to('cuda')\n",
    "nbr_labels = lab_knn.squeeze()\n",
    "s = float(torch.median(-ind_knn[0]).detach().cpu()) # for the median trick\n",
    "\n",
    "\n",
    "# pre-process the img to make it compatible for forward pass\n",
    "to_pil_trans = transforms.ToPILImage()\n",
    "if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "    img = to_pil_trans(img.squeeze().to('cuda'))\n",
    "else:\n",
    "    img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "img = trans(img).unsqueeze(0)\n",
    "lab = int(lab)\n",
    "if img.shape[1]==4:\n",
    "    img = img[:,0,:,:].unsqueeze(0)\n",
    "feature_maps = []\n",
    "out, img_feat = net.module.gradcam_forward(img.to('cuda'),nbr_feats,nbr_labels,layer_id1,s)\n",
    "\n",
    "# show intermediate gradcam\n",
    "out.backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = net.module.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = img_feat.detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(activations.shape[1]):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze().detach().cpu()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= (torch.max(heatmap)+1e-10)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((256,256)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "#         torchvision.transforms.Lambda(center_crop()),\n",
    "        torchvision.transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    ])\n",
    "img = testset.data[img_id]\n",
    "img = T1(to_pil_trans(img.squeeze()))\n",
    "   \n",
    "T2 = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((256,256)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "#         torchvision.transforms.Lambda(center_crop()),\n",
    "    ])\n",
    "heatmap = T2(heatmap)\n",
    "\n",
    "xxx = cm.get_cmap('xxx')\n",
    "heatmap2 = xxx(heatmap.squeeze())\n",
    "\n",
    "img2 = torch.cat((img,1.0*torch.ones(256,256).unsqueeze(0)))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(1.0*img2.permute(1,2,0)+1.0*heatmap2)\n",
    "# plt.imshow(1.2*img2.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0,3,7,10,14,17,20,24,27,30,34,37,40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the final output, but with different target layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # load checkpoint\n",
    "# img_id = 18\n",
    "# img = testset.data[img_id]\n",
    "# lab = testset.targets[img_id]\n",
    "# expt_name = 'vgg16_kmnist_patch_48316'\n",
    "# net = nn.DataParallel(VGG('VGG16',num_channels=1))\n",
    "# net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "# net.eval()\n",
    "# layer_id1 = -1 # vgg layer to viz net.module.features[layer_id1]\n",
    "#                # 0,3,7,10,14,17,20,24,27,30,34,37,40\n",
    "    \n",
    "\n",
    "\n",
    "# # pre-process the img to make it compatible for forward pass\n",
    "# to_pil_trans = transforms.ToPILImage()\n",
    "# if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "#     img = to_pil_trans(img.squeeze().to('cuda'))\n",
    "# else:\n",
    "#     img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "# img = trans(img).unsqueeze(0)\n",
    "# if img.shape[1]==4:\n",
    "#     img = img[:,0,:,:].unsqueeze(0)\n",
    "# feature_maps = []\n",
    "# # out, img_feat = net.module.gradcam_forward(img.to('cuda'),nbr_feats,nbr_labels,layer_id1,s)\n",
    "# out = net(img.to('cuda'))\n",
    "\n",
    "# # compute grad cam masks\n",
    "# targets = [ClassifierOutputTarget(0)]\n",
    "# target_layers = [net.module.features[layer_id1]]\n",
    "\n",
    "# # fetch Class Activation Maps (cams)\n",
    "# cam = EigenCAM(model=net, target_layers=target_layers, use_cuda=True)\n",
    "# grayscale_cams = cam(input_tensor=img, targets=targets, aug_smooth=True, eigen_smooth=True)\n",
    "\n",
    "# # overlay cam on original images\n",
    "# img = img.squeeze().unsqueeze(-1).detach().cpu().numpy()\n",
    "# cam_op = show_cam_on_image(img, grayscale_cams[0]*0.5, use_rgb=True)\n",
    "# img_list = []\n",
    "# img_list.append(cam_op)\n",
    "\n",
    "# # plot overlays\n",
    "# plot_images(img_list,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user hyperparams\n",
    "expt_name = 'vgg16_kmnist_patch_48316'\n",
    "layer_id1 = 42\n",
    "\n",
    "# load model\n",
    "net = nn.DataParallel(VGG('VGG16',num_channels=1))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()\n",
    "\n",
    "# loop over test images\n",
    "for _ in range(30):\n",
    "    img_id = int(random.random()*len(testset.data))\n",
    "    img = testset.data[img_id]\n",
    "    \n",
    "    # pre-process the img to make it compatible for forward pass\n",
    "    to_pil_trans = transforms.ToPILImage()\n",
    "    if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "        img_tensor = to_pil_trans(img.squeeze().to('cuda'))\n",
    "    else:\n",
    "        img_tensor = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "    img_tensor = trans(img_tensor).unsqueeze(0)\n",
    "    if img_tensor.shape[1]==4:\n",
    "        img_tensor = img_tensor[:,0,:,:].unsqueeze(0)\n",
    "        \n",
    "    img_rgb = img_tensor.squeeze().unsqueeze(-1).expand(32,32,3)\n",
    "\n",
    "    # gradCAM code\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "    target_layers = [net.module.features[layer_id1]]\n",
    "\n",
    "    cam = GradCAM(model=net, target_layers=target_layers, use_cuda=True)\n",
    "    grayscale_cams = cam(input_tensor=img_tensor, targets=targets, aug_smooth=False, eigen_smooth=True)\n",
    "    cam_op = show_cam_on_image(np.array(img_rgb), grayscale_cams[0], use_rgb=True)\n",
    "    \n",
    "    img_list = []\n",
    "    img_list.append(img_rgb)\n",
    "    img_list.append(grayscale_cams[0])\n",
    "    img_list.append(cam_op)\n",
    "\n",
    "    # plot results\n",
    "    plot_images(img_list,rows=1,cols=3,titles=['Original Img','Heat Map','Overlay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option-3 SHAP (on final outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user hyperparams\n",
    "expt_name = 'vgg16_kmnist_27437'\n",
    "\n",
    "# load model\n",
    "net = nn.DataParallel(VGG('VGG16',num_channels=1))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()\n",
    "\n",
    "batch = next(iter(testloader))\n",
    "images, _ = batch\n",
    "\n",
    "shap_train_imgs = images[:10].to('cuda')\n",
    "shap_test_imgs = images[10:14].to('cuda')\n",
    "\n",
    "e = shap.DeepExplainer(net, shap_train_imgs)\n",
    "shap_values = e.shap_values(shap_test_imgs)\n",
    "\n",
    "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "test_numpy = np.swapaxes(np.swapaxes(shap_test_imgs.cpu().numpy(), 1, -1), 1, 2)\n",
    "shap.image_plot(shap_numpy, -test_numpy, width=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(shap_test_imgs).shape, len(shap_values), shap_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in shap_train_imgs:\n",
    "    print(x.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option-3 SHAP (on custom intermediate soft-KNN output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# user hyperparams\n",
    "expt_name = 'vgg16_kmnist_27437'\n",
    "layer_id = 0 # vgg layer to viz net.module.features[layer_id]\n",
    "               # 0,3,7,10,14,17,20,24,27,30,34,37,40\n",
    "train_emb_idx = 0 # info_dict['feats'][train_emb_idx]\n",
    "              # 0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "\n",
    "# load model\n",
    "train_embs_pkl_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "net = nn.DataParallel(customVGG2('VGG16', train_embs_pkl_path, layer_id, train_emb_idx, num_channels=1))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()\n",
    "\n",
    "# load batch of images\n",
    "batch = next(iter(testloader))\n",
    "images, _ = batch\n",
    "\n",
    "# prepare shap train and test images\n",
    "shap_train_imgs = images[:100].to('cuda')\n",
    "shap_test_imgs = images[100:102].to('cuda')\n",
    "\n",
    "e = shap.DeepExplainer(net, shap_train_imgs)\n",
    "shap_values = e.shap_values(test_img)\n",
    "\n",
    "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "test_numpy = np.swapaxes(np.swapaxes(test_img.cpu().numpy(), 1, -1), 1, 2)\n",
    "shap.image_plot(shap_numpy, -test_numpy, width=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option-4\n",
    "Using grad-cam for intermediate layers as described in:\n",
    "https://jacobgil.github.io/pytorch-gradcam-book/Pixel%20Attribution%20for%20embeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========user hyper-params==================\n",
    "expt_name = 'vgg16_mnist_patch_34272'\n",
    "net = nn.DataParallel(customVGG('VGG16',num_channels=1))\n",
    "img_id = 5\n",
    "layer_id1 = 0 # vgg layer to viz net.module.features[layer_id1]\n",
    "               # 0,3,7,10,14,17,20,24,27,30,34,37,40\n",
    "layer_id2 = 0 # info_dict['feats'][layer_id2]\n",
    "              # 0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "# ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()\n",
    "# add hook to layer you want to viz    \n",
    "feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "def hook_feat_map(mod, inp, out):\n",
    "    feature_maps.append(torch.reshape(out, (out.shape[0],-1)))\n",
    "    \n",
    "net.module.features[layer_id1].register_forward_hook(hook_feat_map)\n",
    "\n",
    "# get the nearest K neighbours\n",
    "K = 29\n",
    "lp_norm = 1\n",
    "train_embs_pkl_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "\n",
    "img = testset.data[img_id]\n",
    "lab = testset.targets[img_id]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # make img compatible for forward pass\n",
    "    to_pil_trans = transforms.ToPILImage()\n",
    "    if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "        img = to_pil_trans(img.to('cuda'))\n",
    "    else:\n",
    "        img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "    img = trans(img).unsqueeze(0)\n",
    "    if img.shape[1]==4:\n",
    "        img = img[:,0,:,:].unsqueeze(0)\n",
    "        \n",
    "    feature_maps = []\n",
    "    out = torch.sigmoid(net.module.simpleForward(img.to('cuda')))\n",
    "    print(f'Model output: {out}')\n",
    "    \n",
    "    with open(train_embs_pkl_path, 'rb') as handle:            \n",
    "        info_dict = pickle.load(handle)\n",
    "\n",
    "        X_i = feature_maps[0].unsqueeze(1)  # (10000, 1, 784) test set\n",
    "        X_j = info_dict['feats'][layer_id2].unsqueeze(0)  # (1, 60000, 784) train set\n",
    "        if lp_norm==2:\n",
    "            D_ij = ((X_i - X_j) ** 2).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "        elif lp_norm==1:\n",
    "            D_ij = (abs(X_i - X_j)).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "        else:\n",
    "            raise('Invalid lp_norm in arguments!')\n",
    "\n",
    "        ind_knn = torch.topk(-D_ij,K,dim=1)  # Samples <-> Dataset, (N_test, K)\n",
    "        lab_knn = info_dict['labels'][ind_knn[1]]  # (N_test, K) array of integers in [0,9]\n",
    "\n",
    "\n",
    "    # free GPU memory\n",
    "    del info_dict\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_inds = np.array(ind_knn[1][0].detach().cpu())\n",
    "nbr_feats = X_j[0,nbr_inds,:].to('cuda')\n",
    "nbr_labels = lab_knn.squeeze()\n",
    "s = float(torch.median(-ind_knn[0]).detach().cpu()) # for the median trick\n",
    "\n",
    "net.module.nbr_feats = nbr_feats\n",
    "net.module.nbr_labels = nbr_labels\n",
    "net.module.s = s\n",
    "net.module.layer_id = layer_id1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the img to make it compatible for forward pass\n",
    "to_pil_trans = transforms.ToPILImage()\n",
    "if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "    img = to_pil_trans(img.squeeze().to('cuda'))\n",
    "else:\n",
    "    img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "img = trans(img).unsqueeze(0)\n",
    "if img.shape[1]==4:\n",
    "    img = img[:,0,:,:].unsqueeze(0)\n",
    "\n",
    "# compute grad cam masks\n",
    "targets = [ClassifierOutputTarget(0)]\n",
    "target_layers = [net.module.features[layer_id1]]\n",
    "\n",
    "# fetch Class Activation Maps (cams)\n",
    "cam = GradCAMPlusPlus(model=net, target_layers=target_layers, use_cuda=True)\n",
    "grayscale_cams = cam(input_tensor=img, targets=targets, aug_smooth=False, eigen_smooth=True)\n",
    "\n",
    "# overlay cam on original images\n",
    "img = img.squeeze().unsqueeze(-1).detach().cpu().numpy()\n",
    "cam_op = show_cam_on_image(img, grayscale_cams[0], use_rgb=True)\n",
    "img_list = []\n",
    "img_list.append(img)\n",
    "img_list.append(grayscale_cams[0])\n",
    "img_list.append(cam_op)\n",
    "\n",
    "# plot overlays\n",
    "plot_images(img_list,rows=1,cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# code in loop\n",
    "expt_name = 'vgg16_mnist_patch_34272'\n",
    "net = nn.DataParallel(customVGG('VGG16',num_channels=1))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "net.eval()\n",
    "for _ in range(1000):\n",
    "    # ===========user hyper-params==================\n",
    "    img_id = int(random.random()*len(testset.data))\n",
    "    layer_id1 = 40 # vgg layer to viz net.module.features[layer_id1]\n",
    "                   # 0,3,7,10,14,17,20,24,27,30,34,37,40\n",
    "    layer_id2 = 12 # info_dict['feats'][layer_id2]\n",
    "                  # 0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "    # =============================\n",
    "    # add hook to layer you want to viz    \n",
    "    feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "    def hook_feat_map(mod, inp, out):\n",
    "        feature_maps.append(torch.reshape(out, (out.shape[0],-1)))\n",
    "\n",
    "    net.module.features[layer_id1].register_forward_hook(hook_feat_map)\n",
    "\n",
    "    # get the nearest K neighbours\n",
    "    K = 29\n",
    "    lp_norm = 1\n",
    "    train_embs_pkl_path = os.path.join(save_dir,f'{expt_name}.pkl')\n",
    "\n",
    "    img = testset.data[img_id]\n",
    "    lab = testset.targets[img_id]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # make img compatible for forward pass\n",
    "        to_pil_trans = transforms.ToPILImage()\n",
    "        if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "            img = to_pil_trans(img.to('cuda'))\n",
    "        else:\n",
    "            img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "        img = trans(img).unsqueeze(0)\n",
    "        if img.shape[1]==4:\n",
    "            img = img[:,0,:,:].unsqueeze(0)\n",
    "\n",
    "        feature_maps = []\n",
    "        out = torch.sigmoid(net.module.simpleForward(img.to('cuda')))\n",
    "        print(f'Model output: {out}')\n",
    "\n",
    "        with open(train_embs_pkl_path, 'rb') as handle:            \n",
    "            info_dict = pickle.load(handle)\n",
    "\n",
    "            X_i = feature_maps[0].unsqueeze(1)  # (10000, 1, 784) test set\n",
    "            X_j = info_dict['feats'][layer_id2].unsqueeze(0)  # (1, 60000, 784) train set\n",
    "            if lp_norm==2:\n",
    "                D_ij = ((X_i - X_j) ** 2).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "            elif lp_norm==1:\n",
    "                D_ij = (abs(X_i - X_j)).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "            else:\n",
    "                raise('Invalid lp_norm in arguments!')\n",
    "\n",
    "            ind_knn = torch.topk(-D_ij,K,dim=1)  # Samples <-> Dataset, (N_test, K)\n",
    "            lab_knn = info_dict['labels'][ind_knn[1]]  # (N_test, K) array of integers in [0,9]\n",
    "\n",
    "\n",
    "        # free GPU memory\n",
    "        del info_dict\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    nbr_inds = np.array(ind_knn[1][0].detach().cpu())\n",
    "    nbr_feats = X_j[0,nbr_inds,:].to('cuda')\n",
    "    nbr_labels = lab_knn.squeeze()\n",
    "    s = float(torch.median(-ind_knn[0]).detach().cpu()) # for the median trick\n",
    "\n",
    "    net.module.nbr_feats = nbr_feats\n",
    "    net.module.nbr_labels = nbr_labels\n",
    "    net.module.s = s\n",
    "    net.module.layer_id = layer_id1\n",
    "\n",
    "    # pre-process the img to make it compatible for forward pass\n",
    "    to_pil_trans = transforms.ToPILImage()\n",
    "    if dataset=='mnist' or dataset=='kmnist' or dataset=='fmnist':\n",
    "        img = to_pil_trans(img.squeeze().to('cuda'))\n",
    "    else:\n",
    "        img = to_pil_trans(img.permute(2,0,1).to('cuda'))\n",
    "    img = trans(img).unsqueeze(0)\n",
    "    if img.shape[1]==4:\n",
    "        img = img[:,0,:,:].unsqueeze(0)\n",
    "\n",
    "    # compute grad cam masks\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "    target_layers = [net.module.features[layer_id1]]\n",
    "\n",
    "    # fetch Class Activation Maps (cams)\n",
    "    cam = GradCAMPlusPlus(model=net, target_layers=target_layers, use_cuda=True)\n",
    "    grayscale_cams = cam(input_tensor=img, targets=targets, aug_smooth=False, eigen_smooth=True)\n",
    "\n",
    "    # overlay cam on original images\n",
    "    img = img.squeeze().unsqueeze(-1).detach().cpu().numpy()\n",
    "    cam_op = show_cam_on_image(img, grayscale_cams[0], use_rgb=True)\n",
    "    img_list = []\n",
    "    img_list.append(img)\n",
    "    img_list.append(grayscale_cams[0])\n",
    "    img_list.append(cam_op)\n",
    "\n",
    "    # plot overlays\n",
    "    plot_images(img_list,rows=1,cols=3,titles=['Original Img','Heat Map','Overlay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Train Only Initial Layers on Randomized Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# user hyperparams\n",
    "expt_name = 'vgg16_kmnist_patch_48316'\n",
    "num_ch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.DataParallel(VGG('VGG16',num_channels=num_ch))\n",
    "net.load_state_dict(torch.load(os.path.join(save_dir,f'{expt_name}.pt'))['net'])\n",
    "for i in range(10,45,1):\n",
    "    for param in net.module.features[i].parameters():\n",
    "        param.requires_grad = False\n",
    "for param in net.module.classifier.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sanity checking if all gradients false except initial layers\n",
    "for param in net.module.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "net = net.to(device)\n",
    "    \n",
    "if device == 'cuda':\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "\n",
    "# Training\n",
    "def train(epoch, randomize_labels=False):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)):\n",
    "        if randomize_labels:\n",
    "            targets = targets[torch.randperm(targets.shape[0])] # randomize labels\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                 % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(testloader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(2,randomize_labels=True)\n",
    "test(2)\n",
    "scheduler.step()\n",
    "\n",
    "print('Saving..')\n",
    "state = {\n",
    "    'net': net.state_dict(),\n",
    "    'epoch': 2,\n",
    "}\n",
    "#         if not os.path.isdir(f'{args['expt_name']}_checkpoint'):\n",
    "#             os.mkdir('checkpoint')\n",
    "torch.save(state, os.path.join(save_dir,f'{expt_name}_a.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Train Only Final Layers on True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze initial layers\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for i in range(0,10,1):\n",
    "    for param in net.module.features[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sanity checking if all gradients false except initial layers\n",
    "for param in net.module.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "train(epoch,randomize_labels=False)\n",
    "test(epoch)\n",
    "scheduler.step()\n",
    "\n",
    "print('Saving..')\n",
    "state = {\n",
    "    'net': net.state_dict(),\n",
    "    'epoch': epoch,\n",
    "}\n",
    "#         if not os.path.isdir(f'{args['expt_name']}_checkpoint'):\n",
    "#             os.mkdir('checkpoint')\n",
    "torch.save(state, os.path.join(save_dir,f'{expt_name}_b.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'vgg16_mnist_75872'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PDs histogram\n",
    "\n",
    "with open(os.path.join(save_dir,expt_name+'_testPDinfo.pkl'), 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "\n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "correct_preds_arr = (batch_info['preds']==batch_info['labels'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('MNIST', fontsize=25)\n",
    "plt.ylabel('No. of Images', fontsize=25)\n",
    "plt.xlabel('VGG16 Layers', fontsize=25)\n",
    "if model=='resnet18':\n",
    "    plt.xlim((0,18))\n",
    "elif model=='vgg16':\n",
    "    plt.xlim((0,16))\n",
    "plt.ylim((0,80))\n",
    "plt.hist(batch_info['pd'][correct_preds_arr ],bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],color='g',alpha=0.55)\n",
    "plt.hist(batch_info['pd'][~correct_preds_arr ],bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],color='r',alpha=0.55)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.savefig(os.path.join(save_dir,expt_name+'_PDplot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'vgg16_fmnist_88507'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PDs histogram\n",
    "\n",
    "with open(os.path.join(save_dir,expt_name+'_testPDinfo.pkl'), 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "\n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "correct_preds_arr = (batch_info['preds']==batch_info['labels'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('FMNIST', fontsize=25)\n",
    "plt.ylabel('No. of Images', fontsize=25)\n",
    "plt.xlabel('VGG16 Layers', fontsize=25)\n",
    "if model=='resnet18':\n",
    "    plt.xlim((0,18))\n",
    "elif model=='vgg16':\n",
    "    plt.xlim((0,16))\n",
    "plt.ylim((0,80))\n",
    "plt.hist(batch_info['pd'][correct_preds_arr ],bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],color='g',alpha=0.55)\n",
    "plt.hist(batch_info['pd'][~correct_preds_arr ],bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],color='r',alpha=0.55)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.savefig(os.path.join(save_dir,expt_name+'_PDplot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'vgg16_cifar10_18394'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PDs histogram\n",
    "\n",
    "with open(os.path.join(save_dir,expt_name+'_testPDinfo.pkl'), 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "\n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "correct_preds_arr = (batch_info['preds']==batch_info['labels'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('CIFAR10', fontsize=25)\n",
    "plt.ylabel('No. of Images', fontsize=25)\n",
    "plt.xlabel('VGG16 Layers', fontsize=25)\n",
    "if model=='resnet18':\n",
    "    plt.xlim((0,18))\n",
    "elif model=='vgg16':\n",
    "    plt.xlim((0,16))\n",
    "plt.ylim((0,80))\n",
    "plt.hist(batch_info['pd'],bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],color='g',alpha=0.55)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.savefig(os.path.join(save_dir,expt_name+'_PDplot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'vgg16_kmnist_27437'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PDs histogram\n",
    "\n",
    "with open(os.path.join(save_dir,expt_name+'_testPDinfo.pkl'), 'rb') as handle:\n",
    "    batch_info = pickle.load(handle)\n",
    "\n",
    "batch_info['pd'] = np.array(batch_info['pd'])\n",
    "batch_info['labels'] = np.array(batch_info['labels'])\n",
    "batch_info['preds'] = np.array(batch_info['preds'])\n",
    "correct_preds_arr = (batch_info['preds']==batch_info['labels'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('KMNIST w/o patch', fontsize=25)\n",
    "plt.ylabel('No. of Images', fontsize=25)\n",
    "plt.xlabel('VGG16 Layers', fontsize=25)\n",
    "if model=='resnet18':\n",
    "    plt.xlim((0,18))\n",
    "elif model=='vgg16':\n",
    "    plt.xlim((0,16))\n",
    "plt.ylim((0,80))\n",
    "plt.hist(batch_info['pd'][correct_preds_arr ],bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],color='g',alpha=0.55)\n",
    "plt.hist(batch_info['pd'][~correct_preds_arr ],bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],color='r',alpha=0.55)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.savefig(os.path.join(save_dir,expt_name+'_PDplot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/xxx/home/xxx/xxx/xxx/projects/shortcut_detection_and_mitigation/data/mimic/full/train.csv')\n",
    "df[df['pneumothorax']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "212023/7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over test images\n",
    "invalid_counter = 0 # for invalid predictions (last layer mode != model output)\n",
    "loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=4)\n",
    "for test_id, (img,lab) in enumerate(tqdm(loader)):\n",
    "\n",
    "    batch_info['imgs'].append(img)\n",
    "    img, lab = img.to(device), lab.to(device)\n",
    "    with torch.no_grad():\n",
    "        # lab = int(lab)\n",
    "        feature_maps = []\n",
    "        out = net(img)\n",
    "        print(f'OUT = {out}')\n",
    "        print(f'Model output: {out.max()}')\n",
    "        batch_info['preds'].append(int(out.argmax()))\n",
    "        batch_info['pred_probs'].append(float(torch.nn.functional.softmax(out).max()))\n",
    "        batch_info['labels'].append(lab)\n",
    "\n",
    "        print_memory_profile('Model forward pass')\n",
    "        with open(train_embs_pkl_path, 'rb') as handle:            \n",
    "            info_dict = pickle.load(handle)\n",
    "            print_memory_profile('Pickle load')\n",
    "\n",
    "            # loop over layers in densenet, and compute KNN for this test image\n",
    "            knn_preds_mode = []  # layer-wise final KNN classification preds   \n",
    "            knn_preds_prob = []\n",
    "            for layer_id,feat in tqdm(enumerate(feature_maps)):\n",
    "                X_i = feat.unsqueeze(1)  # (10000, 1, 784) test set\n",
    "                X_j = info_dict['feats'][layer_id].unsqueeze(0)  # (1, 60000, 784) train set\n",
    "                if lp_norm==2:\n",
    "                    D_ij = ((X_i - X_j) ** 2).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "                elif lp_norm==1:\n",
    "                    D_ij = (abs(X_i - X_j)).sum(-1)  # (10000, 60000) symbolic matrix of squared L2 distances\n",
    "                else:\n",
    "                    raise('Invalid lp_norm in arguments!')\n",
    "\n",
    "                ind_knn = torch.topk(-D_ij,K,dim=1)  # Samples <-> Dataset, (N_test, K)\n",
    "                lab_knn = info_dict['labels'][ind_knn[1]]  # (N_test, K) array of integers in [0,9]\n",
    "#                 print(f'!!!!!!test_img:{test_id}, nbrs in layer {layer_id}: {ind_knn[1]}')\n",
    "                mode = int(lab_knn.squeeze().mode()[0])\n",
    "                knn_preds_mode.append(mode)\n",
    "                knn_preds_prob.append(float((lab_knn==mode).float().mean()))\n",
    "\n",
    "            print_memory_profile('Pickle batch processed')\n",
    "\n",
    "            # free GPU memory\n",
    "            del info_dict\n",
    "            torch.cuda.empty_cache()\n",
    "            print_memory_profile('After GPU memory freed') \n",
    "\n",
    "            print('Test Image: %d' %(test_id))\n",
    "            print(f'knn_preds_mode: {knn_preds_mode}')\n",
    "            print(f'knn_preds_prob: {knn_preds_prob}')\n",
    "            print(f'label: {lab}')\n",
    "            print(f'pred: {int(out.argmax())}')\n",
    "            print('\\n')\n",
    "            batch_info['layers_knn_prob'].append(knn_preds_prob)\n",
    "            batch_info['layers_knn_mode'].append(knn_preds_mode)\n",
    "            if int(out.argmax())==knn_preds_mode[-1]: # PD accurate\n",
    "                if knn_pos_thresh==0.5 and knn_neg_thresh==0.5:\n",
    "                    batch_info['pd'].append(compute_pred_depth(knn_preds_mode))\n",
    "                else:\n",
    "                    raise('Code not ready yet! Compute pred arr function also has to be updated!')\n",
    "            else: # PD inaccurate, KNN pred doesn't match model pred\n",
    "                print('Invalid datapoint: last_layer_mode != model_output')\n",
    "                invalid_counter += 1\n",
    "                batch_info['pd'].append(-99)\n",
    "print(f'Invalid Counts Ratio: {invalid_counter}/{num_test_imgs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
